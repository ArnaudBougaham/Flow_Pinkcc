{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Image Segmentation Lab\n",
    "## Teacher Version\n",
    "\n",
    "This notebook demonstrates a complete pipeline for medical image segmentation using CT scans. We'll focus on:\n",
    "- Comprehensive Exploratory Data Analysis (EDA)\n",
    "- Data preprocessing and augmentation\n",
    "- Implementation of a U-Net architecture\n",
    "- K-fold cross-validation\n",
    "- Model evaluation and visualization\n",
    "\n",
    "### Resources:\n",
    "- [U-Net Paper](https://arxiv.org/abs/1505.04597)\n",
    "- [Medical Image Segmentation Tutorial](https://www.kaggle.com/code/iezepov/fast-ai-2018-lesson-3-notes)\n",
    "- [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install nibabel scikit-learn torch torchvision matplotlib seaborn\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import nibabel as nib\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Initial Exploration\n",
    "\n",
    "The dataset is organized in the following structure:\n",
    "- Train_Phase_2/\n",
    "  - TCGA-* (various TCGA cases)\n",
    "  - Each case contains CT images and corresponding segmentation masks\n",
    "\n",
    "We'll work with a subset of 100 cases to ensure manageable training time and memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_data_paths(base_dir, num_cases=100):\n",
    "    \"\"\"Get paths for CT and mask files from the dataset\"\"\"\n",
    "    # Get all TCGA folders\n",
    "    tcga_folders = [f for f in os.listdir(base_dir) if f.startswith('TCGA-')]\n",
    "    \n",
    "    # Randomly select num_cases\n",
    "    selected_folders = np.random.choice(tcga_folders, num_cases, replace=False)\n",
    "    \n",
    "    ct_paths = []\n",
    "    mask_paths = []\n",
    "    \n",
    "    for folder in selected_folders:\n",
    "        folder_path = os.path.join(base_dir, folder)\n",
    "        # Assuming CT images are in .nii.gz format\n",
    "        ct_files = [f for f in os.listdir(folder_path) if f.endswith('.nii.gz') and not f.endswith('_mask.nii.gz')]\n",
    "        mask_files = [f for f in os.listdir(folder_path) if f.endswith('_mask.nii.gz')]\n",
    "        \n",
    "        for ct_file, mask_file in zip(ct_files, mask_files):\n",
    "            ct_paths.append(os.path.join(folder_path, ct_file))\n",
    "            mask_paths.append(os.path.join(folder_path, mask_file))\n",
    "    \n",
    "    return ct_paths, mask_paths\n",
    "\n",
    "# Load data paths\n",
    "base_dir = 'Train_Phase_2'  # Update this path to your local directory\n",
    "ct_paths, mask_paths = get_data_paths(base_dir, num_cases=100)\n",
    "\n",
    "print(f\"Total number of cases: {len(ct_paths)}\")\n",
    "print(f\"Sample CT path: {ct_paths[0]}\")\n",
    "print(f\"Sample mask path: {mask_paths[0]}\")\n",
    "\n",
    "# Load and analyze a sample case\n",
    "sample_ct = nib.load(ct_paths[0]).get_fdata()\n",
    "sample_mask = nib.load(mask_paths[0]).get_fdata()\n",
    "\n",
    "print(f\"\\nSample case information:\")\n",
    "print(f\"CT shape: {sample_ct.shape}\")\n",
    "print(f\"CT value range: [{sample_ct.min():.2f}, {sample_ct.max():.2f}]\")\n",
    "print(f\"Mask shape: {sample_mask.shape}\")\n",
    "print(f\"Mask value range: [{sample_mask.min():.2f}, {sample_mask.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Exploratory Data Analysis\n",
    "\n",
    "Let's perform a comprehensive analysis of our data to understand:\n",
    "- Intensity distributions\n",
    "- Slice-wise analysis\n",
    "- Class balance\n",
    "- Spatial characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def analyze_intensity_distribution(ct_img, mask):\n",
    "    \"\"\"Analyze intensity distributions of CT and mask\"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # CT intensity distribution\n",
    "    plt.subplot(121)\n",
    "    sns.histplot(ct_img.flatten(), bins=50)\n",
    "    plt.title('CT Intensity Distribution')\n",
    "    plt.xlabel('Intensity')\n",
    "    \n",
    "    # Mask distribution\n",
    "    plt.subplot(122)\n",
    "    sns.histplot(mask.flatten(), bins=2)\n",
    "    plt.title('Mask Distribution')\n",
    "    plt.xlabel('Class')\n",
    "    plt.show()\n",
    "\n",
    "def analyze_slices(ct_img, mask, num_slices=5):\n",
    "    \"\"\"Analyze different slices of the volume\"\"\"\n",
    "    middle = ct_img.shape[2] // 2\n",
    "    step = ct_img.shape[2] // (num_slices + 1)\n",
    "    \n",
    "    plt.figure(figsize=(15, 3*num_slices))\n",
    "    for i in range(num_slices):\n",
    "        slice_idx = middle + (i - num_slices//2) * step\n",
    "        \n",
    "        plt.subplot(num_slices, 3, i*3 + 1)\n",
    "        plt.imshow(ct_img[:, :, slice_idx], cmap='gray')\n",
    "        plt.title(f'CT Slice {slice_idx}')\n",
    "        \n",
    "        plt.subplot(num_slices, 3, i*3 + 2)\n",
    "        plt.imshow(mask[:, :, slice_idx], cmap='gray')\n",
    "        plt.title(f'Mask Slice {slice_idx}')\n",
    "        \n",
    "        plt.subplot(num_slices, 3, i*3 + 3)\n",
    "        plt.imshow(ct_img[:, :, slice_idx], cmap='gray')\n",
    "        plt.imshow(mask[:, :, slice_idx], alpha=0.3, cmap='Reds')\n",
    "        plt.title(f'Overlay Slice {slice_idx}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Perform analysis\n",
    "analyze_intensity_distribution(ct_img, mask)\n",
    "analyze_slices(ct_img, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Augmentation\n",
    "\n",
    "We'll implement:\n",
    "- Intensity normalization\n",
    "- Data augmentation\n",
    "- Slice extraction\n",
    "- Class balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class MedicalImageDataset(Dataset):\n",
    "    def __init__(self, ct_paths, mask_paths, transform=None, slice_idx=None):\n",
    "        self.ct_paths = ct_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transform = transform\n",
    "        self.slice_idx = slice_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ct_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load data\n",
    "        ct_img = nib.load(self.ct_paths[idx]).get_fdata()\n",
    "        mask = nib.load(self.mask_paths[idx]).get_fdata()\n",
    "        \n",
    "        # Extract slice if specified\n",
    "        if self.slice_idx is not None:\n",
    "            ct_img = ct_img[:, :, self.slice_idx]\n",
    "            mask = mask[:, :, self.slice_idx]\n",
    "        else:\n",
    "            # If no specific slice is requested, use the middle slice\n",
    "            middle_slice = ct_img.shape[2] // 2\n",
    "            ct_img = ct_img[:, :, middle_slice]\n",
    "            mask = mask[:, :, middle_slice]\n",
    "        \n",
    "        # Normalize CT image to [0, 1]\n",
    "        ct_img = (ct_img - ct_img.min()) / (ct_img.max() - ct_img.min())\n",
    "        \n",
    "        # Convert to torch tensors\n",
    "        ct_img = torch.from_numpy(ct_img).float()\n",
    "        mask = torch.from_numpy(mask).float()\n",
    "        \n",
    "        if self.transform:\n",
    "            ct_img = self.transform(ct_img)\n",
    "            mask = self.transform(mask)\n",
    "            \n",
    "        return ct_img, mask\n",
    "\n",
    "# Update data loading function\n",
    "def get_data_loaders(ct_paths, mask_paths, batch_size=8, num_folds=5):\n",
    "    \"\"\"Create data loaders for K-fold cross validation\"\"\"\n",
    "    # Create KFold splitter\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Create datasets and dataloaders for each fold\n",
    "    fold_loaders = []\n",
    "    for train_idx, val_idx in kf.split(ct_paths):\n",
    "        train_ct = [ct_paths[i] for i in train_idx]\n",
    "        train_mask = [mask_paths[i] for i in train_idx]\n",
    "        val_ct = [ct_paths[i] for i in val_idx]\n",
    "        val_mask = [mask_paths[i] for i in val_idx]\n",
    "        \n",
    "        train_dataset = MedicalImageDataset(train_ct, train_mask, transform=train_transform)\n",
    "        val_dataset = MedicalImageDataset(val_ct, val_mask, transform=val_transform)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        fold_loaders.append((train_loader, val_loader))\n",
    "    \n",
    "    return fold_loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net Model Implementation\n",
    "\n",
    "We'll implement a U-Net architecture with:\n",
    "- Encoder (downsampling) path\n",
    "- Decoder (upsampling) path\n",
    "- Skip connections\n",
    "- Batch normalization\n",
    "- Residual connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"Double convolution block with batch normalization\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels=1, n_classes=1):\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        # Encoder (downsampling path)\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(64, 128)\n",
    "        )\n",
    "        self.down2 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(128, 256)\n",
    "        )\n",
    "        self.down3 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(256, 512)\n",
    "        )\n",
    "        self.down4 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(512, 1024)\n",
    "        )\n",
    "\n",
    "        # Decoder (upsampling path)\n",
    "        self.up1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.up_conv1 = DoubleConv(1024, 512)\n",
    "        self.up2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.up_conv2 = DoubleConv(512, 256)\n",
    "        self.up3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.up_conv3 = DoubleConv(256, 128)\n",
    "        self.up4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.up_conv4 = DoubleConv(128, 64)\n",
    "\n",
    "        # Output layer\n",
    "        self.outc = nn.Conv2d(64, n_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "\n",
    "        # Decoder with skip connections\n",
    "        x = self.up1(x5)\n",
    "        x = torch.cat([x4, x], dim=1)\n",
    "        x = self.up_conv1(x)\n",
    "\n",
    "        x = self.up2(x)\n",
    "        x = torch.cat([x3, x], dim=1)\n",
    "        x = self.up_conv2(x)\n",
    "\n",
    "        x = self.up3(x)\n",
    "        x = torch.cat([x2, x], dim=1)\n",
    "        x = self.up_conv3(x)\n",
    "\n",
    "        x = self.up4(x)\n",
    "        x = torch.cat([x1, x], dim=1)\n",
    "        x = self.up_conv4(x)\n",
    "\n",
    "        return torch.sigmoid(self.outc(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Setup and K-fold Cross Validation\n",
    "\n",
    "We'll implement:\n",
    "- K-fold cross validation\n",
    "- Training and validation functions\n",
    "- Loss functions and metrics\n",
    "- Learning rate scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_data_loaders(ct_dir, mask_dir, batch_size=8, num_folds=5):\n",
    "    \"\"\"Create data loaders for K-fold cross validation\"\"\"\n",
    "    # Get all file paths\n",
    "    ct_files = sorted([os.path.join(ct_dir, f) for f in os.listdir(ct_dir) if f.endswith('.nii.gz')])\n",
    "    mask_files = sorted([os.path.join(mask_dir, f) for f in os.listdir(mask_dir) if f.endswith('.nii.gz')])\n",
    "    \n",
    "    # Create KFold splitter\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Create datasets and dataloaders for each fold\n",
    "    fold_loaders = []\n",
    "    for train_idx, val_idx in kf.split(ct_files):\n",
    "        train_ct = [ct_files[i] for i in train_idx]\n",
    "        train_mask = [mask_files[i] for i in train_idx]\n",
    "        val_ct = [ct_files[i] for i in val_idx]\n",
    "        val_mask = [mask_files[i] for i in val_idx]\n",
    "        \n",
    "        train_dataset = MedicalImageDataset(train_ct, train_mask, transform=train_transform)\n",
    "        val_dataset = MedicalImageDataset(val_ct, val_mask, transform=val_transform)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        fold_loaders.append((train_loader, val_loader))\n",
    "    \n",
    "    return fold_loaders\n",
    "\n",
    "def dice_coefficient(pred, target):\n",
    "    \"\"\"Calculate Dice coefficient\"\"\"\n",
    "    smooth = 1e-5\n",
    "    pred = pred.view(-1)\n",
    "    target = target.view(-1)\n",
    "    intersection = (pred * target).sum()\n",
    "    return (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_dice = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        total_loss += loss.item()\n",
    "        total_dice += dice_coefficient(output, target).item()\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f'Batch {batch_idx}/{len(loader)}, Loss: {loss.item():.4f}')\n",
    "    \n",
    "    return total_loss / len(loader), total_dice / len(loader)\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    \"\"\"Validate the model\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_dice = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_dice += dice_coefficient(output, target).item()\n",
    "            \n",
    "    return total_loss / len(loader), total_dice / len(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop and Monitoring\n",
    "\n",
    "We'll implement:\n",
    "- Training loop with K-fold cross validation\n",
    "- Learning rate scheduling\n",
    "- Model checkpointing\n",
    "- Progress monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 50\n",
    "learning_rate = 1e-4\n",
    "batch_size = 8\n",
    "num_folds = 5\n",
    "\n",
    "# Get data loaders\n",
    "fold_loaders = get_data_loaders('Data/CT', 'Data/Segmentation', batch_size=batch_size, num_folds=num_folds)\n",
    "\n",
    "# Training loop with K-fold cross validation\n",
    "fold_metrics = []\n",
    "for fold, (train_loader, val_loader) in enumerate(fold_loaders):\n",
    "    print(f'\\nTraining fold {fold + 1}/{num_folds}')\n",
    "    \n",
    "    # Initialize model, criterion, and optimizer\n",
    "    model = UNet(n_channels=1, n_classes=1).to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)\n",
    "    \n",
    "    # Initialize metrics tracking\n",
    "    best_dice = 0\n",
    "    fold_history = {'train_loss': [], 'train_dice': [], 'val_loss': [], 'val_dice': []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch + 1}/{num_epochs}')\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_dice = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_dice = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_dice)\n",
    "        \n",
    "        # Store metrics\n",
    "        fold_history['train_loss'].append(train_loss)\n",
    "        fold_history['train_dice'].append(train_dice)\n",
    "        fold_history['val_loss'].append(val_loss)\n",
    "        fold_history['val_dice'].append(val_dice)\n",
    "        \n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Dice: {train_dice:.4f}')\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Dice: {val_dice:.4f}')\n",
    "        \n",
    "        # Save best model\n",
    "        if val_dice > best_dice:\n",
    "            best_dice = val_dice\n",
    "            torch.save(model.state_dict(), f'best_model_fold_{fold + 1}.pth')\n",
    "            print(f'New best model saved with Dice score: {best_dice:.4f}')\n",
    "    \n",
    "    fold_metrics.append(fold_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation and Visualization\n",
    "\n",
    "We'll:\n",
    "- Load the best model\n",
    "- Evaluate on test set\n",
    "- Visualize predictions\n",
    "- Analyze model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def plot_training_history(fold_metrics):\n",
    "    \"\"\"Plot training history for all folds\"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot training loss\n",
    "    plt.subplot(221)\n",
    "    for i, metrics in enumerate(fold_metrics):\n",
    "        plt.plot(metrics['train_loss'], label=f'Fold {i+1}')\n",
    "    plt.title('Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot validation loss\n",
    "    plt.subplot(222)\n",
    "    for i, metrics in enumerate(fold_metrics):\n",
    "        plt.plot(metrics['val_loss'], label=f'Fold {i+1}')\n",
    "    plt.title('Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot training dice\n",
    "    plt.subplot(223)\n",
    "    for i, metrics in enumerate(fold_metrics):\n",
    "        plt.plot(metrics['train_dice'], label=f'Fold {i+1}')\n",
    "    plt.title('Training Dice Coefficient')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Dice')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot validation dice\n",
    "    plt.subplot(224)\n",
    "    for i, metrics in enumerate(fold_metrics):\n",
    "        plt.plot(metrics['val_dice'], label=f'Fold {i+1}')\n",
    "    plt.title('Validation Dice Coefficient')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Dice')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_predictions(model, loader, device, num_samples=3):\n",
    "    \"\"\"Visualize model predictions\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            # Visualize results for first batch\n",
    "            for i in range(min(num_samples, len(data))):\n",
    "                plt.figure(figsize=(15, 5))\n",
    "                \n",
    "                plt.subplot(131)\n",
    "                plt.imshow(data[i].cpu().squeeze(), cmap='gray')\n",
    "                plt.title('Input CT')\n",
    "                plt.axis('off')\n",
    "                \n",
    "                plt.subplot(132)\n",
    "                plt.imshow(target[i].cpu().squeeze(), cmap='gray')\n",
    "                plt.title('Ground Truth')\n",
    "                plt.axis('off')\n",
    "                \n",
    "                plt.subplot(133)\n",
    "                plt.imshow(output[i].cpu().squeeze(), cmap='gray')\n",
    "                plt.title('Prediction')\n",
    "                plt.axis('off')\n",
    "                \n",
    "                plt.show()\n",
    "            break\n",
    "\n",
    "# Plot training history\n",
    "plot_training_history(fold_metrics)\n",
    "\n",
    "# Load best model and visualize predictions\n",
    "best_model = UNet(n_channels=1, n_classes=1).to(device)\n",
    "best_model.load_state_dict(torch.load('best_model_fold_1.pth'))\n",
    "visualize_predictions(best_model, val_loader, device)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
