{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aq41EyRt3bzG",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "# üî¨ Ovarian Cancer Segmentation Lab\n",
        "\n",
        "Welcome to this comprehensive lab on medical image segmentation for ovarian cancer detection! In this lab, you'll work with volumetric CT scan data to develop an advanced deep learning solution for automated cancer tissue identification.\n",
        "\n",
        "## üìã Task Overview\n",
        "Your goal is to develop a 3D U-Net model that can accurately segment CT volumes into three distinct classes:\n",
        "- **Class 0**: Background tissue\n",
        "- **Class 1**: Primary ovarian cancer\n",
        "- **Class 2**: Metastatic tissue\n",
        "\n",
        "## üéØ Learning Objectives\n",
        "By completing this lab, you will:\n",
        "- Master working with medical imaging data in NIfTI format\n",
        "- Implement and understand the 3D U-Net architecture\n",
        "- Learn effective training strategies for medical image segmentation\n",
        "- Develop skills in evaluating and validating medical imaging models\n",
        "- Gain practical experience with real-world medical data\n",
        "\n",
        "## üîç Clinical Relevance\n",
        "Accurate segmentation of ovarian cancer tissues is crucial for:\n",
        "- Early detection and diagnosis\n",
        "- Treatment planning and monitoring\n",
        "- Assessment of disease progression\n",
        "- Research and clinical trials\n",
        "\n",
        "Let's dive in and build a solution that could make a real difference in healthcare! üöÄ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d08DKLq3bzH"
      },
      "source": [
        "# 1Ô∏è‚É£ Environment Setup and Dependencies\n",
        "\n",
        "Before we begin our implementation, let's set up our development environment with all necessary packages and configurations.\n",
        "\n",
        "## üì¶ Required Packages\n",
        "We'll be using the following key libraries:\n",
        "- **PyTorch**: For deep learning model implementation\n",
        "- **NiBabel**: For handling medical imaging data in NIfTI format\n",
        "- **scikit-image**: For image processing and transformations\n",
        "- **NumPy**: For numerical computations\n",
        "- **Matplotlib**: For visualization\n",
        "\n",
        "## üñ•Ô∏è Hardware Requirements\n",
        "- GPU with CUDA support (recommended)\n",
        "- Sufficient RAM for 3D volume processing\n",
        "- Adequate storage for medical imaging data\n",
        "\n",
        "## ‚öôÔ∏è Configuration\n",
        "We'll set up:\n",
        "- CUDA device if available\n",
        "- Random seeds for reproducibility\n",
        "- Memory optimization settings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install numpy --quiet\n",
        "!pip install scipy --quiet\n",
        "!pip install scikit-learn --quiet\n",
        "!pip install scikit-image nibabel gdown torch torchvision --quiet\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nibabel as nib\n",
        "from skimage import transform\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Set up GPU if available\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"WARNING: CUDA is not available. Please make sure to enable GPU in Runtime > Change runtime type\")\n",
        "    print(\"Current device: CPU\")\n",
        "else:\n",
        "    # Set default tensor type to CUDA\n",
        "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "    device = torch.device('cuda')\n",
        "    print(f\"Using device: {device}\")\n",
        "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Available memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 2Ô∏è‚É£ Data Acquisition and Preprocessing\n",
        "\n",
        "## üì• Dataset Download\n",
        "First, we'll download our dataset containing CT scans and their corresponding segmentation masks. The data is stored in NIfTI format (`.nii.gz`), which is commonly used for medical imaging.\n",
        "\n",
        "## üóÇÔ∏è Data Organization\n",
        "The dataset is organized into two main directories:\n",
        "- `Data_Subsample/CT/`: Contains the CT scan volumes\n",
        "- `Data_Subsample/Segmentation/`: Contains the corresponding segmentation masks\n",
        "\n",
        "## üíæ Data Loading\n",
        "Let's download and extract the dataset, then verify our data structure:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download and extract dataset\n",
        "file_id = '1Wo4h6ZVIFygVvqd68ApwWIdPQk3l7gkO'\n",
        "output = 'Data_Subsample.zip'\n",
        "\n",
        "if not os.path.exists('Data_Subsample.zip'):\n",
        "    import subprocess\n",
        "    subprocess.run(['gdown', '--id', file_id, '-O', output])\n",
        "\n",
        "# Extract data if not already extracted\n",
        "if not os.path.exists('Data_Subsample'):\n",
        "    import zipfile\n",
        "    with zipfile.ZipFile(output, 'r') as zip_ref:\n",
        "        zip_ref.extractall('.')\n",
        "\n",
        "# List available files\n",
        "ct_files = sorted([f for f in os.listdir('Data_Subsample/CT') if f.endswith('.nii.gz')])\n",
        "seg_files = sorted([f for f in os.listdir('Data_Subsample/Segmentation') if f.endswith('.nii.gz')])\n",
        "\n",
        "print(f'Number of CT volumes: {len(ct_files)}')\n",
        "print(f'Number of segmentation masks: {len(seg_files)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 3Ô∏è‚É£ Loss Functions and Metrics\n",
        "\n",
        "For medical image segmentation, choosing appropriate loss functions is crucial. We'll implement two key components:\n",
        "\n",
        "## üéØ Dice Loss\n",
        "The Dice coefficient (also known as F1 score) is particularly useful for segmentation tasks because it:\n",
        "- Handles class imbalance well\n",
        "- Focuses on overlap between predictions and ground truth\n",
        "- Ranges from 0 (no overlap) to 1 (perfect overlap)\n",
        "\n",
        "## üîÑ Combined Loss\n",
        "We'll combine Dice Loss with weighted Cross-Entropy to:\n",
        "- Balance between pixel-wise and region-based segmentation quality\n",
        "- Handle class imbalance through dynamic class weights\n",
        "- Provide smoother gradients during training\n",
        "\n",
        "Let's implement these loss functions:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DiceLoss(nn.Module):\n",
        "    \"\"\"Dice Loss for multi-class 3D segmentation\"\"\"\n",
        "    def __init__(self, smooth=1e-5):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def forward(self, predictions, targets):\n",
        "        # predictions shape: (batch_size, n_classes, d1, d2, d3)\n",
        "        # targets shape: (batch_size, d1, d2, d3)\n",
        "\n",
        "        # Convert predictions to probabilities\n",
        "        predictions = F.softmax(predictions, dim=1)\n",
        "\n",
        "        # One-hot encode targets\n",
        "        n_classes = predictions.shape[1]\n",
        "        one_hot_targets = F.one_hot(targets, n_classes).permute(0, 4, 1, 2, 3).float()\n",
        "\n",
        "        # Calculate Dice score for each class\n",
        "        numerator = 2 * (predictions * one_hot_targets).sum(dim=(2, 3, 4))\n",
        "        denominator = predictions.sum(dim=(2, 3, 4)) + one_hot_targets.sum(dim=(2, 3, 4))\n",
        "        dice_scores = (numerator + self.smooth) / (denominator + self.smooth)\n",
        "\n",
        "        # Average over classes and batch\n",
        "        return 1 - dice_scores.mean()\n",
        "\n",
        "class CombinedLoss(nn.Module):\n",
        "    \"\"\"Combined Dice and weighted Cross-Entropy loss with focus on cancer classes\"\"\"\n",
        "    def __init__(self, smooth=1e-5, ce_weight=0.5, background_weight=0.1):\n",
        "        super(CombinedLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "        self.ce_weight = ce_weight\n",
        "        self.background_weight = background_weight\n",
        "        self.dice_loss = DiceLoss(smooth=smooth)\n",
        "\n",
        "    def forward(self, predictions, targets):\n",
        "        # Calculate class weights with reduced background weight\n",
        "        n_classes = predictions.shape[1]\n",
        "        class_counts = torch.bincount(targets.flatten(), minlength=n_classes).float()\n",
        "        total_pixels = class_counts.sum()\n",
        "        \n",
        "        # Modify weights to focus on cancer classes\n",
        "        class_weights = torch.zeros_like(class_counts)\n",
        "        class_weights[0] = self.background_weight  # Background class\n",
        "        class_weights[1:] = (1.0 - self.background_weight) / (n_classes - 1)  # Cancer classes\n",
        "        \n",
        "        # Scale weights by inverse frequency within cancer classes\n",
        "        cancer_counts = class_counts[1:]  # Counts for cancer classes\n",
        "        if cancer_counts.sum() > 0:  # Avoid division by zero\n",
        "            cancer_weights = total_pixels / (cancer_counts * n_classes + self.smooth)\n",
        "            cancer_weights = cancer_weights / cancer_weights.sum()  # Normalize\n",
        "            class_weights[1:] *= cancer_weights\n",
        "        \n",
        "        class_weights = class_weights.to(predictions.device)\n",
        "\n",
        "        # Dice Loss (focusing on cancer classes)\n",
        "        dice_loss = self.dice_loss(predictions, targets)\n",
        "\n",
        "        # Weighted Cross Entropy Loss\n",
        "        ce_loss = F.cross_entropy(predictions, targets, weight=class_weights)\n",
        "\n",
        "        # Combine losses\n",
        "        return dice_loss + self.ce_weight * ce_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 4Ô∏è‚É£ Dataset and Model Architecture\n",
        "\n",
        "## üìä Dataset Implementation\n",
        "We'll create a custom PyTorch Dataset class that:\n",
        "- Loads and preprocesses 3D medical images\n",
        "- Handles data normalization and augmentation\n",
        "- Manages batch creation for training\n",
        "\n",
        "## üèóÔ∏è Model Architecture\n",
        "Our 3D U-Net implementation includes:\n",
        "- Encoder path with increasing feature channels\n",
        "- Decoder path with skip connections\n",
        "- Advanced features:\n",
        "  - Batch normalization for stable training\n",
        "  - Residual connections for better gradient flow\n",
        "  - Dropout for regularization\n",
        "  - Squeeze-and-Excitation blocks for channel attention\n",
        "\n",
        "Let's implement these components:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class OvarianCancerDataset(Dataset):\n",
        "    \"\"\"Dataset class for 3D ovarian cancer segmentation\"\"\"\n",
        "    def __init__(self, ct_files, seg_files, target_xy_size=128, is_train=True):\n",
        "        self.ct_files = ct_files\n",
        "        self.seg_files = seg_files\n",
        "        self.target_xy_size = target_xy_size\n",
        "        self.is_train = is_train\n",
        "\n",
        "    def normalize_volume(self, volume):\n",
        "        \"\"\"Normalize volume to [0,1] range with robust scaling\"\"\"\n",
        "        p1, p99 = np.percentile(volume, (1, 99))\n",
        "        volume = np.clip(volume, p1, p99)\n",
        "        volume = (volume - p1) / (p99 - p1)\n",
        "        return volume\n",
        "\n",
        "    def load_volume(self, file_path):\n",
        "        \"\"\"Load a NIfTI volume and return its data\"\"\"\n",
        "        return nib.load(file_path).get_fdata()\n",
        "\n",
        "    def resize_volume(self, volume, is_mask=False):\n",
        "        \"\"\"Resize volume while preserving z-dimension\"\"\"\n",
        "        resized_slices = []\n",
        "        for z in range(volume.shape[2]):\n",
        "            if is_mask:\n",
        "                # Nearest neighbor for masks to preserve labels\n",
        "                slice_2d = transform.resize(volume[:,:,z], \n",
        "                                         (self.target_xy_size, self.target_xy_size), \n",
        "                                         order=0, \n",
        "                                         preserve_range=True,\n",
        "                                         anti_aliasing=False)\n",
        "            else:\n",
        "                # Bilinear interpolation for CT images\n",
        "                slice_2d = transform.resize(volume[:,:,z], \n",
        "                                         (self.target_xy_size, self.target_xy_size), \n",
        "                                         order=1,\n",
        "                                         preserve_range=True,\n",
        "                                         anti_aliasing=True)\n",
        "            resized_slices.append(slice_2d)\n",
        "        return np.stack(resized_slices, axis=2)\n",
        "\n",
        "    def augment_volume(self, ct_vol, seg_vol):\n",
        "        \"\"\"Apply data augmentation\"\"\"\n",
        "        if not self.is_train:\n",
        "            return ct_vol, seg_vol\n",
        "\n",
        "        # Random flip\n",
        "        if np.random.random() > 0.5:\n",
        "            ct_vol = np.flip(ct_vol, axis=0)\n",
        "            seg_vol = np.flip(seg_vol, axis=0)\n",
        "        if np.random.random() > 0.5:\n",
        "            ct_vol = np.flip(ct_vol, axis=1)\n",
        "            seg_vol = np.flip(seg_vol, axis=1)\n",
        "\n",
        "        # Random rotation\n",
        "        if np.random.random() > 0.5:\n",
        "            angle = np.random.uniform(-15, 15)\n",
        "            for z in range(ct_vol.shape[2]):\n",
        "                ct_vol[:,:,z] = transform.rotate(ct_vol[:,:,z], angle, \n",
        "                                               mode='reflect', \n",
        "                                               preserve_range=True)\n",
        "                seg_vol[:,:,z] = transform.rotate(seg_vol[:,:,z], angle, \n",
        "                                                mode='reflect', \n",
        "                                                order=0, \n",
        "                                                preserve_range=True)\n",
        "\n",
        "        return ct_vol, seg_vol\n",
        "\n",
        "    def preprocess_volume(self, ct_path, seg_path):\n",
        "        \"\"\"Load and preprocess a single volume pair\"\"\"\n",
        "        # Load volumes\n",
        "        ct_vol = self.load_volume(ct_path)\n",
        "        seg_vol = self.load_volume(seg_path)\n",
        "\n",
        "        # Resize volumes while preserving z-dimension\n",
        "        ct_vol = self.resize_volume(ct_vol, is_mask=False)\n",
        "        seg_vol = self.resize_volume(seg_vol, is_mask=True)\n",
        "\n",
        "        # Normalize CT volume\n",
        "        ct_vol = self.normalize_volume(ct_vol)\n",
        "\n",
        "        # Apply augmentation\n",
        "        if self.is_train:\n",
        "            ct_vol, seg_vol = self.augment_volume(ct_vol, seg_vol)\n",
        "\n",
        "        # Ensure segmentation values are integers\n",
        "        seg_vol = np.round(seg_vol).astype(np.int64)\n",
        "\n",
        "        return ct_vol, seg_vol\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ct_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ct_path = os.path.join('Data_Subsample/CT', self.ct_files[idx])\n",
        "        seg_path = os.path.join('Data_Subsample/Segmentation', self.seg_files[idx])\n",
        "\n",
        "        # Load and preprocess\n",
        "        ct_vol, seg_vol = self.preprocess_volume(ct_path, seg_path)\n",
        "\n",
        "        # Convert to torch tensors and add channel dimension\n",
        "        ct_vol = torch.FloatTensor(ct_vol).unsqueeze(0)\n",
        "        seg_vol = torch.LongTensor(seg_vol)\n",
        "        \n",
        "        return ct_vol, seg_vol\n",
        "\n",
        "# Split data into training and validation sets\n",
        "train_ct, val_ct, train_seg, val_seg = train_test_split(\n",
        "    ct_files, seg_files, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = OvarianCancerDataset(train_ct, train_seg)\n",
        "val_dataset = OvarianCancerDataset(val_ct, val_seg)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, \n",
        "    batch_size=1, \n",
        "    shuffle=True,  # Let PyTorch handle shuffling\n",
        "    num_workers=0,  # Run in main process\n",
        "    pin_memory=True if torch.cuda.is_available() else False\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset, \n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    num_workers=0,  # Run in main process\n",
        "    pin_memory=True if torch.cuda.is_available() else False\n",
        ")\n",
        "\n",
        "print(f'Training samples: {len(train_dataset)}')\n",
        "print(f'Validation samples: {len(val_dataset)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SEBlock(nn.Module):\n",
        "    \"\"\"Squeeze-and-Excitation block for channel attention\"\"\"\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super().__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channels, channels // reduction),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channels // reduction, channels),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1, 1)\n",
        "        return x * y\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"Enhanced double convolution block with SE attention\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.se = SEBlock(out_channels)\n",
        "        self.residual = nn.Sequential(\n",
        "            nn.Conv3d(in_channels, out_channels, kernel_size=1),\n",
        "            nn.BatchNorm3d(out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        main = self.double_conv(x)\n",
        "        main = self.se(main)\n",
        "        residual = self.residual(x)\n",
        "        return F.relu(main + residual)\n",
        "\n",
        "class UNet3D(nn.Module):\n",
        "    \"\"\"Enhanced 3D U-Net with SE attention, residual connections, and deep supervision\"\"\"\n",
        "    def __init__(self, in_channels=1, out_channels=3, features=[32, 64, 128, 256]):\n",
        "        super(UNet3D, self).__init__()\n",
        "        self.encoder = nn.ModuleList()\n",
        "        self.decoder = nn.ModuleList()\n",
        "        self.deep_supervision = nn.ModuleList()\n",
        "        self.pool = nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Encoder\n",
        "        in_channels_temp = in_channels\n",
        "        for feature in features:\n",
        "            self.encoder.append(DoubleConv(in_channels_temp, feature))\n",
        "            in_channels_temp = feature\n",
        "\n",
        "        # Decoder with deep supervision\n",
        "        for i, feature in enumerate(reversed(features[:-1])):\n",
        "            # Upsampling\n",
        "            self.decoder.append(\n",
        "                nn.Sequential(\n",
        "                    nn.ConvTranspose3d(\n",
        "                        features[features.index(feature)+1],\n",
        "                        feature,\n",
        "                        kernel_size=2,\n",
        "                        stride=2\n",
        "                    ),\n",
        "                    nn.BatchNorm3d(feature),\n",
        "                    nn.ReLU(inplace=True)\n",
        "                )\n",
        "            )\n",
        "            # Double conv after concatenation\n",
        "            self.decoder.append(DoubleConv(feature * 2, feature))\n",
        "            \n",
        "            # Deep supervision outputs\n",
        "            self.deep_supervision.append(\n",
        "                nn.Conv3d(feature, out_channels, kernel_size=1)\n",
        "            )\n",
        "\n",
        "        self.bottleneck = DoubleConv(features[-2], features[-1])\n",
        "        self.final_conv = nn.Conv3d(features[0], out_channels, kernel_size=1)\n",
        "\n",
        "        # Advanced regularization\n",
        "        self.dropout = nn.Dropout3d(p=0.3)\n",
        "        self.spatial_dropout = nn.Dropout3d(p=0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip_connections = []\n",
        "        deep_outputs = []\n",
        "\n",
        "        # Encoder\n",
        "        for encoder in self.encoder[:-1]:\n",
        "            x = encoder(x)\n",
        "            x = self.spatial_dropout(x)  # Spatial dropout for feature map augmentation\n",
        "            skip_connections.append(x)\n",
        "            x = self.pool(x)\n",
        "            x = self.dropout(x)\n",
        "\n",
        "        x = self.bottleneck(x)\n",
        "\n",
        "        # Decoder with deep supervision\n",
        "        skip_connections = skip_connections[::-1]\n",
        "        for idx in range(0, len(self.decoder), 2):\n",
        "            x = self.decoder[idx](x)\n",
        "            skip = skip_connections[idx//2]\n",
        "\n",
        "            # Handle different sizes\n",
        "            if x.shape != skip.shape:\n",
        "                x = F.interpolate(x, size=skip.shape[2:])\n",
        "\n",
        "            concat_skip = torch.cat((skip, x), dim=1)\n",
        "            x = self.decoder[idx+1](concat_skip)\n",
        "            x = self.dropout(x)\n",
        "\n",
        "            # Deep supervision output\n",
        "            deep_out = self.deep_supervision[idx//2](x)\n",
        "            deep_outputs.append(deep_out)\n",
        "\n",
        "        # Final output\n",
        "        final_out = self.final_conv(x)\n",
        "        \n",
        "        if self.training:\n",
        "            # During training, return main output and deep supervision outputs\n",
        "            return final_out, deep_outputs\n",
        "        else:\n",
        "            # During inference, return only the main output\n",
        "            return final_out\n",
        "\n",
        "# Initialize model and move to GPU if available\n",
        "model = UNet3D(in_channels=1, out_channels=3)\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "print(f\"Model architecture:\\n{model}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 5Ô∏è‚É£ Training and Evaluation\n",
        "\n",
        "## üèÉ‚Äç‚ôÇÔ∏è Training Process\n",
        "Our training pipeline includes:\n",
        "- Batch-wise training with GPU acceleration\n",
        "- Learning rate scheduling with ReduceLROnPlateau\n",
        "- Early stopping to prevent overfitting\n",
        "- Model checkpointing to save best weights\n",
        "- Memory optimization with periodic cache clearing\n",
        "\n",
        "## üìà Evaluation Metrics\n",
        "We'll monitor:\n",
        "- Dice coefficient per class\n",
        "- Overall segmentation accuracy\n",
        "- Class-wise precision and recall\n",
        "- Training and validation loss curves\n",
        "\n",
        "## üîç Visualization\n",
        "During and after training, we'll visualize:\n",
        "- Sample predictions on validation data\n",
        "- Training progress and learning curves\n",
        "- Segmentation overlays on CT slices\n",
        "\n",
        "Let's implement the training loop and evaluation functions:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_epoch(model, loader, optimizer, criterion, deep_weight=0.5):\n",
        "    \"\"\"Train the model for one epoch with deep supervision\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    num_batches = len(loader)\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(loader):\n",
        "        # Move data to GPU if available\n",
        "        if torch.cuda.is_available():\n",
        "            data = data.cuda()\n",
        "            target = target.cuda()\n",
        "\n",
        "        # Clear gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass with deep supervision\n",
        "        main_output, deep_outputs = model(data)\n",
        "        \n",
        "        # Calculate main loss\n",
        "        main_loss = criterion(main_output, target)\n",
        "        \n",
        "        # Calculate deep supervision losses\n",
        "        deep_loss = 0\n",
        "        for deep_out in deep_outputs:\n",
        "            # Resize deep supervision output to match target size if needed\n",
        "            if deep_out.shape[2:] != target.shape[1:]:\n",
        "                deep_out = F.interpolate(deep_out, size=target.shape[1:], mode='trilinear', align_corners=False)\n",
        "            deep_loss += criterion(deep_out, target)\n",
        "        \n",
        "        # Combine losses\n",
        "        loss = main_loss + deep_weight * (deep_loss / len(deep_outputs))\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update metrics\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Print progress and clear cache\n",
        "        if batch_idx % 5 == 0:\n",
        "            print(f'Batch {batch_idx}/{num_batches}, Loss: {loss.item():.4f}')\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()  # Clear GPU cache periodically\n",
        "\n",
        "    return total_loss / num_batches\n",
        "\n",
        "def validate(model, loader, criterion):\n",
        "    \"\"\"Validate the model\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    dice_scores = []\n",
        "    num_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in loader:\n",
        "            # Move data to GPU if available\n",
        "            if torch.cuda.is_available():\n",
        "                data = data.cuda()\n",
        "                target = target.cuda()\n",
        "            \n",
        "            # Model returns only main output during validation\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            \n",
        "            # Calculate Dice score\n",
        "            pred = F.softmax(output, dim=1)\n",
        "            pred = torch.argmax(pred, dim=1)\n",
        "            for i in range(3):  # 3 classes\n",
        "                dice = calculate_dice_score(pred == i, target == i)\n",
        "                dice_scores.append(dice)\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "    avg_dice = sum(dice_scores) / len(dice_scores)\n",
        "    return total_loss / num_batches, avg_dice\n",
        "\n",
        "def calculate_dice_score(pred, target):\n",
        "    \"\"\"Calculate Dice score for binary masks\"\"\"\n",
        "    intersection = (pred & target).sum().float()\n",
        "    union = pred.sum() + target.sum()\n",
        "    if union == 0:\n",
        "        return 1.0  # Define empty as perfect match\n",
        "    return (2.0 * intersection / union).item()\n",
        "\n",
        "def predict_volume(model, ct_volume):\n",
        "    \"\"\"Generate predictions for a single volume\"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        if torch.cuda.is_available():\n",
        "            ct_volume = ct_volume.cuda()\n",
        "        pred = model(ct_volume.unsqueeze(0))\n",
        "        pred = F.softmax(pred, dim=1)\n",
        "        pred = torch.argmax(pred, dim=1)\n",
        "    return pred[0].cpu().numpy()\n",
        "\n",
        "# Training setup with focus on cancer classes\n",
        "criterion = CombinedLoss(\n",
        "    ce_weight=0.7,  # Balance between Dice and CE\n",
        "    background_weight=0.1,  # Reduce focus on background class\n",
        "    smooth=1e-5\n",
        ")\n",
        "\n",
        "# Optimizer with gradient clipping\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=1e-3,\n",
        "    weight_decay=0.01,\n",
        "    amsgrad=True  # Use AMSGrad variant\n",
        ")\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr=1e-3,\n",
        "    epochs=50,\n",
        "    steps_per_epoch=len(train_loader),\n",
        "    pct_start=0.3,  # Warm-up period\n",
        "    div_factor=25,  # Initial lr = max_lr/25\n",
        "    final_div_factor=1000,  # Min lr = initial_lr/1000\n",
        ")\n",
        "\n",
        "# Training loop with improved monitoring\n",
        "n_epochs = 50  # Increased epochs\n",
        "best_val_dice = 0.0  # Track best Dice score instead of loss\n",
        "patience = 10  # Increased patience\n",
        "patience_counter = 0\n",
        "history = {'train_loss': [], 'val_loss': [], 'val_dice': [], 'lr': []}\n",
        "\n",
        "print(\"Starting training...\")\n",
        "for epoch in range(n_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{n_epochs}\")\n",
        "    \n",
        "    # Training phase with deep supervision\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, criterion, deep_weight=0.5)\n",
        "    print(f\"Training Loss: {train_loss:.4f}\")\n",
        "    \n",
        "    # Validation phase\n",
        "    val_loss, val_dice = validate(model, val_loader, criterion)\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, Validation Dice: {val_dice:.4f}\")\n",
        "    \n",
        "    # Learning rate scheduling\n",
        "    scheduler.step()\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    print(f\"Current learning rate: {current_lr:.2e}\")\n",
        "    \n",
        "    # Update history\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_dice'].append(val_dice)\n",
        "    history['lr'].append(current_lr)\n",
        "    \n",
        "    # Model checkpointing based on Dice score\n",
        "    if val_dice > best_val_dice:\n",
        "        best_val_dice = val_dice\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'best_dice': best_val_dice,\n",
        "            'history': history\n",
        "        }, 'best_model.pth')\n",
        "        patience_counter = 0\n",
        "        print(f\"Saved new best model with Dice score: {best_val_dice:.4f}!\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "    \n",
        "    # Early stopping\n",
        "    if patience_counter >= patience:\n",
        "        print(f\"\\nEarly stopping triggered after {epoch+1} epochs\")\n",
        "        print(f\"Best validation Dice score: {best_val_dice:.4f}\")\n",
        "        break\n",
        "    \n",
        "    # Clear GPU memory\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 6Ô∏è‚É£ Discussion and Future Work\n",
        "\n",
        "## üîç Technical Analysis\n",
        "Consider and discuss the following aspects of your implementation:\n",
        "\n",
        "### Data Challenges\n",
        "- What difficulties did you encounter with the medical imaging data?\n",
        "- How effective was your preprocessing pipeline?\n",
        "- What additional data augmentation techniques could be beneficial?\n",
        "\n",
        "### Model Performance\n",
        "- How well did the model segment different tissue types?\n",
        "- What were the main sources of errors?\n",
        "- How could the architecture be improved?\n",
        "\n",
        "## üè• Clinical Impact\n",
        "Reflect on the clinical applications:\n",
        "\n",
        "### Current Capabilities\n",
        "- How reliable is the model for clinical use?\n",
        "- What are the limitations of the current implementation?\n",
        "- How does it compare to human expert performance?\n",
        "\n",
        "### Future Improvements\n",
        "- What additional validation would be needed for clinical deployment?\n",
        "- How could the model be integrated into clinical workflows?\n",
        "- What safety measures should be implemented?\n",
        "\n",
        "## üöÄ Next Steps\n",
        "Consider these potential improvements:\n",
        "\n",
        "### Technical Enhancements\n",
        "- Implement additional data augmentation techniques\n",
        "- Experiment with different model architectures\n",
        "- Add uncertainty quantification\n",
        "- Optimize for inference speed\n",
        "\n",
        "### Clinical Integration\n",
        "- Develop a user-friendly interface\n",
        "- Add reporting and visualization tools\n",
        "- Implement quality assurance measures\n",
        "- Design clinical validation studies\n",
        "\n",
        "Write your answers and reflections below:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1Jz7yec3bzO"
      },
      "source": [
        "# 9. Discussion Questions\n",
        "\n",
        "Please answer the following questions based on your implementation and results:\n",
        "\n",
        "1. **Data Analysis**\n",
        "   - What challenges did you encounter with the medical imaging data?\n",
        "   - How did you handle class imbalance?\n",
        "\n",
        "2. **Model Performance**\n",
        "   - How well did the model perform on different classes?\n",
        "   - What were the main sources of error?\n",
        "\n",
        "3. **Clinical Relevance**\n",
        "   - How might this model be useful in a clinical setting?\n",
        "   - What additional validation would be needed?\n",
        "\n",
        "4. **Improvements**\n",
        "   - What modifications could improve the model's performance?\n",
        "   - How could the preprocessing pipeline be enhanced?\n",
        "\n",
        "Write your answers below:\n",
        "\n",
        "1. Data Analysis:\n",
        "   > Your answer here\n",
        "\n",
        "2. Model Performance:\n",
        "   > Your answer here\n",
        "\n",
        "3. Clinical Relevance:\n",
        "   > Your answer here\n",
        "\n",
        "4. Improvements:\n",
        "   > Your answer here\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
