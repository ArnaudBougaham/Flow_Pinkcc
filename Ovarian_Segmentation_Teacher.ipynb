{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Ovarian Cancer Segmentation Lab\n",
    "\n",
    "This lab focuses on medical image segmentation for ovarian cancer detection using CT scans. You will work with volumetric medical data (NIfTI format) to build and train a U-Net model for segmenting different types of cancer tissues.\n",
    "\n",
    "## Task Overview\n",
    "You will segment CT volumes into three classes:\n",
    "- Class 0: Background\n",
    "- Class 1: Primary ovarian cancer\n",
    "- Class 2: Metastasis\n",
    "\n",
    "## ðŸŽ¯ Learning Objectives\n",
    "- Work with medical imaging data in NIfTI format\n",
    "- Implement a 3D U-Net architecture\n",
    "- Train a segmentation model\n",
    "- Evaluate medical imaging results\n",
    "\n",
    "Let's begin! ðŸš€\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 1. Environment Setup\n",
    "\n",
    "First, let's install the required packages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies in the correct order\n",
    "!pip install numpy==1.24.3 --quiet\n",
    "!pip install torch torchvision --quiet\n",
    "!pip install nibabel matplotlib scikit-image gdown --quiet\n",
    "!pip install monai --quiet\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "from skimage import transform\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from monai.losses import DiceLoss\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Download and Extraction\n",
    "\n",
    "Download and extract the dataset containing CT volumes and segmentation masks:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data if not already present\n",
    "file_id = '1Wo4h6ZVIFygVvqd68ApwWIdPQk3l7gkO'\n",
    "output = 'Data_Subsample.zip'\n",
    "\n",
    "if not os.path.exists('Data_Subsample.zip'):\n",
    "    !gdown --id $file_id -O $output\n",
    "\n",
    "# Extract data if not already extracted\n",
    "if not os.path.exists('Data_Subsample'):\n",
    "    !unzip -o Data_Subsample.zip\n",
    "\n",
    "# List available files\n",
    "ct_files = sorted([f for f in os.listdir('Data_Subsample/CT') if f.endswith('.nii.gz')])\n",
    "seg_files = sorted([f for f in os.listdir('Data_Subsample/Segmentation') if f.endswith('.nii.gz')])\n",
    "\n",
    "print(f'Number of CT volumes: {len(ct_files)}')\n",
    "print(f'Number of segmentation masks: {len(seg_files)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Let's explore the data structure and visualize some examples.\n",
    "\n",
    "### Questions to consider:\n",
    "1. What are the typical dimensions of the CT volumes?\n",
    "2. How are the classes distributed in the segmentation masks?\n",
    "3. What preprocessing steps might be necessary?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_volume(file_path):\n",
    "    \"\"\"Load a NIfTI volume and return its data\"\"\"\n",
    "    return nib.load(file_path).get_fdata()\n",
    "\n",
    "def plot_slices(ct_volume, seg_mask=None, slice_nums=None, cmap='gray'):\n",
    "    \"\"\"Plot multiple slices from a volume with optional segmentation overlay\"\"\"\n",
    "    if slice_nums is None:\n",
    "        slice_nums = [ct_volume.shape[2]//2]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(slice_nums), figsize=(15, 5))\n",
    "    if len(slice_nums) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for ax, slice_num in zip(axes, slice_nums):\n",
    "        ax.imshow(ct_volume[:,:,slice_num], cmap=cmap)\n",
    "        if seg_mask is not None:\n",
    "            # Create a masked array for the segmentation\n",
    "            mask_slice = seg_mask[:,:,slice_num]\n",
    "            ax.imshow(mask_slice, alpha=0.3, cmap='jet')\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'Slice {slice_num}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Load and examine first volume\n",
    "ct_path = os.path.join('Data_Subsample/CT', ct_files[0])\n",
    "seg_path = os.path.join('Data_Subsample/Segmentation', seg_files[0])\n",
    "\n",
    "ct_vol = load_volume(ct_path)\n",
    "seg_vol = load_volume(seg_path)\n",
    "\n",
    "print('CT volume shape:', ct_vol.shape)\n",
    "print('Segmentation mask shape:', seg_vol.shape)\n",
    "print('\\nUnique classes in segmentation:', np.unique(seg_vol))\n",
    "\n",
    "# Plot middle slices\n",
    "middle_slice = ct_vol.shape[2]//2\n",
    "plot_slices(ct_vol, seg_vol, [middle_slice-20, middle_slice, middle_slice+20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Preprocessing\n",
    "\n",
    "We'll implement several preprocessing steps:\n",
    "1. Intensity normalization\n",
    "2. Resampling to a common size\n",
    "3. Data augmentation\n",
    "\n",
    "### Questions to consider:\n",
    "1. Why is normalization important for medical images?\n",
    "2. What are appropriate augmentation techniques for 3D medical data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_volume(volume):\n",
    "    \"\"\"Normalize volume to [0,1] range\"\"\"\n",
    "    min_val = np.min(volume)\n",
    "    max_val = np.max(volume)\n",
    "    if max_val - min_val == 0:\n",
    "        return volume\n",
    "    return (volume - min_val) / (max_val - min_val)\n",
    "\n",
    "def preprocess_volume(ct_path, seg_path, target_shape=(128, 128, 128)):\n",
    "    \"\"\"Load and preprocess a single volume pair\"\"\"\n",
    "    # Load volumes\n",
    "    ct_vol = load_volume(ct_path)\n",
    "    seg_vol = load_volume(seg_path)\n",
    "    \n",
    "    # Normalize CT volume\n",
    "    ct_vol = normalize_volume(ct_vol)\n",
    "    \n",
    "    # Resample to target shape\n",
    "    if ct_vol.shape != target_shape:\n",
    "        ct_vol = transform.resize(ct_vol, target_shape, mode='constant', anti_aliasing=True)\n",
    "        seg_vol = transform.resize(seg_vol, target_shape, mode='constant', order=0, anti_aliasing=False)\n",
    "    \n",
    "    return ct_vol, seg_vol\n",
    "\n",
    "# Example preprocessing\n",
    "ct_processed, seg_processed = preprocess_volume(ct_path, seg_path)\n",
    "print('Processed shapes:', ct_processed.shape, seg_processed.shape)\n",
    "print('Value ranges - CT:', ct_processed.min(), ct_processed.max(),\n",
    "      '\\nSegmentation:', seg_processed.min(), seg_processed.max())\n",
    "\n",
    "# Visualize processed data\n",
    "plot_slices(ct_processed, seg_processed, [64])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Dataset and DataLoader\n",
    "\n",
    "Create a PyTorch dataset for efficient data handling:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OvarianCancerDataset(Dataset):\n",
    "    def __init__(self, ct_files, seg_files, transform=None):\n",
    "        self.ct_files = ct_files\n",
    "        self.seg_files = seg_files\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ct_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        ct_path = os.path.join('Data_Subsample/CT', self.ct_files[idx])\n",
    "        seg_path = os.path.join('Data_Subsample/Segmentation', self.seg_files[idx])\n",
    "        \n",
    "        # Load and preprocess\n",
    "        ct_vol, seg_vol = preprocess_volume(ct_path, seg_path)\n",
    "        \n",
    "        # Convert to torch tensors\n",
    "        ct_vol = torch.FloatTensor(ct_vol).unsqueeze(0)  # Add channel dimension\n",
    "        seg_vol = torch.LongTensor(seg_vol)\n",
    "        \n",
    "        if self.transform:\n",
    "            ct_vol = self.transform(ct_vol)\n",
    "        \n",
    "        return ct_vol, seg_vol\n",
    "\n",
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_ct, val_ct, train_seg, val_seg = train_test_split(\n",
    "    ct_files, seg_files, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = OvarianCancerDataset(train_ct, train_seg)\n",
    "val_dataset = OvarianCancerDataset(val_ct, val_seg)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2)\n",
    "\n",
    "print(f'Training samples: {len(train_dataset)}')\n",
    "print(f'Validation samples: {len(val_dataset)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Model Architecture\n",
    "\n",
    "Implement a simplified 3D U-Net for segmentation:\n",
    "\n",
    "### Questions to consider:\n",
    "1. Why is U-Net particularly suitable for medical image segmentation?\n",
    "2. What modifications might improve performance?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet3D(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=3):\n",
    "        super(UNet3D, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, 16, 3, padding=1),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.enc2 = nn.Sequential(\n",
    "            nn.MaxPool3d(2),\n",
    "            nn.Conv3d(16, 32, 3, padding=1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.dec1 = nn.Sequential(\n",
    "            nn.ConvTranspose3d(32, 16, 2, stride=2),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.Conv3d(32, 16, 3, padding=1),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(16, out_channels, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(e1)\n",
    "        \n",
    "        # Decoder\n",
    "        d1 = self.dec1(e2)\n",
    "        d2 = self.dec2(torch.cat([d1, e1], dim=1))\n",
    "        \n",
    "        return d2\n",
    "\n",
    "# Initialize model\n",
    "model = UNet3D().to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Training Loop\n",
    "\n",
    "Set up the training process with appropriate loss functions and optimization:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Training setup\n",
    "criterion = DiceLoss(softmax=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 10\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
    "    val_loss = validate(model, val_loader, criterion)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{n_epochs}:')\n",
    "    print(f'Train Loss: {train_loss:.4f}')\n",
    "    print(f'Val Loss: {val_loss:.4f}')\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Evaluation and Visualization\n",
    "\n",
    "Evaluate the model and visualize results:\n",
    "\n",
    "### Questions to consider:\n",
    "1. How well does the model segment different classes?\n",
    "2. What are the clinical implications of false positives/negatives?\n",
    "3. How could the model be improved?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_volume(model, ct_volume):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(ct_volume.unsqueeze(0).to(device))\n",
    "        pred = F.softmax(pred, dim=1)\n",
    "        pred = torch.argmax(pred, dim=1)\n",
    "    return pred[0].cpu().numpy()\n",
    "\n",
    "# Load a validation sample\n",
    "val_ct, val_seg = val_dataset[0]\n",
    "pred_seg = predict_volume(model, val_ct)\n",
    "\n",
    "# Visualize results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "slice_idx = val_ct.shape[2]//2\n",
    "\n",
    "axes[0].imshow(val_ct[0, :, :, slice_idx], cmap='gray')\n",
    "axes[0].set_title('CT Slice')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(val_seg[:, :, slice_idx], cmap='jet')\n",
    "axes[1].set_title('True Segmentation')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(pred_seg[:, :, slice_idx], cmap='jet')\n",
    "axes[2].set_title('Predicted Segmentation')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Discussion Questions\n",
    "\n",
    "Please answer the following questions based on your implementation and results:\n",
    "\n",
    "1. **Data Analysis**\n",
    "   - What challenges did you encounter with the medical imaging data?\n",
    "   - How did you handle class imbalance?\n",
    "\n",
    "2. **Model Performance**\n",
    "   - How well did the model perform on different classes?\n",
    "   - What were the main sources of error?\n",
    "\n",
    "3. **Clinical Relevance**\n",
    "   - How might this model be useful in a clinical setting?\n",
    "   - What additional validation would be needed?\n",
    "\n",
    "4. **Improvements**\n",
    "   - What modifications could improve the model's performance?\n",
    "   - How could the preprocessing pipeline be enhanced?\n",
    "\n",
    "Write your answers below:\n",
    "\n",
    "1. Data Analysis:\n",
    "   > Your answer here\n",
    "\n",
    "2. Model Performance:\n",
    "   > Your answer here\n",
    "\n",
    "3. Clinical Relevance:\n",
    "   > Your answer here\n",
    "\n",
    "4. Improvements:\n",
    "   > Your answer here\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
