{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aq41EyRt3bzG",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "# ðŸ”¬ Ovarian Cancer Segmentation Lab\n",
        "\n",
        "Welcome to this comprehensive lab on medical image segmentation for ovarian cancer detection! In this lab, you'll work with volumetric CT scan data to develop an advanced deep learning solution for automated cancer tissue identification.\n",
        "\n",
        "## ðŸ“‹ Task Overview\n",
        "Your goal is to develop a 3D U-Net model that can accurately segment CT volumes into three distinct classes:\n",
        "- **Class 0**: Background tissue\n",
        "- **Class 1**: Primary ovarian cancer\n",
        "- **Class 2**: Metastatic tissue\n",
        "\n",
        "## ðŸŽ¯ Learning Objectives\n",
        "By completing this lab, you will:\n",
        "- Master working with medical imaging data in NIfTI format\n",
        "- Implement and understand the 3D U-Net architecture\n",
        "- Learn effective training strategies for medical image segmentation\n",
        "- Develop skills in evaluating and validating medical imaging models\n",
        "- Gain practical experience with real-world medical data\n",
        "\n",
        "## ðŸ” Clinical Relevance\n",
        "Accurate segmentation of ovarian cancer tissues is crucial for:\n",
        "- Early detection and diagnosis\n",
        "- Treatment planning and monitoring\n",
        "- Assessment of disease progression\n",
        "- Research and clinical trials\n",
        "\n",
        "Let's dive in and build a solution that could make a real difference in healthcare! ðŸš€\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d08DKLq3bzH"
      },
      "source": [
        "# 1ï¸âƒ£ Environment Setup and Dependencies\n",
        "\n",
        "Before we begin our implementation, let's set up our development environment with all necessary packages and configurations.\n",
        "\n",
        "## ðŸ“¦ Required Packages\n",
        "We'll be using the following key libraries:\n",
        "- **PyTorch**: For deep learning model implementation\n",
        "- **NiBabel**: For handling medical imaging data in NIfTI format\n",
        "- **scikit-image**: For image processing and transformations\n",
        "- **NumPy**: For numerical computations\n",
        "- **Matplotlib**: For visualization\n",
        "\n",
        "## ðŸ–¥ï¸ Hardware Requirements\n",
        "- GPU with CUDA support (recommended)\n",
        "- Sufficient RAM for 3D volume processing\n",
        "- Adequate storage for medical imaging data\n",
        "\n",
        "## âš™ï¸ Configuration\n",
        "We'll set up:\n",
        "- CUDA device if available\n",
        "- Random seeds for reproducibility\n",
        "- Memory optimization settings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install numpy --quiet\n",
        "!pip install scipy --quiet\n",
        "!pip install scikit-learn --quiet\n",
        "!pip install scikit-image nibabel gdown torch torchvision --quiet\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nibabel as nib\n",
        "from skimage import transform\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Set up GPU if available\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"WARNING: CUDA is not available. Please make sure to enable GPU in Runtime > Change runtime type\")\n",
        "    print(\"Current device: CPU\")\n",
        "else:\n",
        "    # Set default tensor type to CUDA\n",
        "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "    device = torch.device('cuda')\n",
        "    print(f\"Using device: {device}\")\n",
        "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Available memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 2ï¸âƒ£ Data Acquisition and Preprocessing\n",
        "\n",
        "## ðŸ“¥ Dataset Download\n",
        "First, we'll download our dataset containing CT scans and their corresponding segmentation masks. The data is stored in NIfTI format (`.nii.gz`), which is commonly used for medical imaging.\n",
        "\n",
        "## ðŸ—‚ï¸ Data Organization\n",
        "The dataset is organized into two main directories:\n",
        "- `Data_Subsample/CT/`: Contains the CT scan volumes\n",
        "- `Data_Subsample/Segmentation/`: Contains the corresponding segmentation masks\n",
        "\n",
        "## ðŸ’¾ Data Loading\n",
        "Let's download and extract the dataset, then verify our data structure:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download and extract dataset\n",
        "file_id = '1Wo4h6ZVIFygVvqd68ApwWIdPQk3l7gkO'\n",
        "output = 'Data_Subsample.zip'\n",
        "\n",
        "if not os.path.exists('Data_Subsample.zip'):\n",
        "    import subprocess\n",
        "    subprocess.run(['gdown', '--id', file_id, '-O', output])\n",
        "\n",
        "# Extract data if not already extracted\n",
        "if not os.path.exists('Data_Subsample'):\n",
        "    import zipfile\n",
        "    with zipfile.ZipFile(output, 'r') as zip_ref:\n",
        "        zip_ref.extractall('.')\n",
        "\n",
        "# List available files\n",
        "ct_files = sorted([f for f in os.listdir('Data_Subsample/CT') if f.endswith('.nii.gz')])\n",
        "seg_files = sorted([f for f in os.listdir('Data_Subsample/Segmentation') if f.endswith('.nii.gz')])\n",
        "\n",
        "print(f'Number of CT volumes: {len(ct_files)}')\n",
        "print(f'Number of segmentation masks: {len(seg_files)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 3ï¸âƒ£ Loss Functions and Metrics\n",
        "\n",
        "For medical image segmentation, choosing appropriate loss functions is crucial. We'll implement two key components:\n",
        "\n",
        "## ðŸŽ¯ Dice Loss\n",
        "The Dice coefficient (also known as F1 score) is particularly useful for segmentation tasks because it:\n",
        "- Handles class imbalance well\n",
        "- Focuses on overlap between predictions and ground truth\n",
        "- Ranges from 0 (no overlap) to 1 (perfect overlap)\n",
        "\n",
        "## ðŸ”„ Combined Loss\n",
        "We'll combine Dice Loss with weighted Cross-Entropy to:\n",
        "- Balance between pixel-wise and region-based segmentation quality\n",
        "- Handle class imbalance through dynamic class weights\n",
        "- Provide smoother gradients during training\n",
        "\n",
        "Let's implement these loss functions:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DiceLoss(nn.Module):\n",
        "    \"\"\"Dice Loss for multi-class 2D segmentation\"\"\"\n",
        "    def __init__(self, smooth=1e-5):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def forward(self, predictions, targets):\n",
        "        # predictions shape: (batch_size, n_classes, height, width)\n",
        "        # targets shape: (batch_size, height, width)\n",
        "\n",
        "        # Convert predictions to probabilities\n",
        "        predictions = F.softmax(predictions, dim=1)\n",
        "\n",
        "        # One-hot encode targets\n",
        "        n_classes = predictions.shape[1]\n",
        "        one_hot_targets = F.one_hot(targets, n_classes).permute(0, 3, 1, 2).float()\n",
        "\n",
        "        # Calculate Dice score for each class\n",
        "        numerator = 2 * (predictions * one_hot_targets).sum(dim=(2, 3))\n",
        "        denominator = predictions.sum(dim=(2, 3)) + one_hot_targets.sum(dim=(2, 3))\n",
        "        dice_scores = (numerator + self.smooth) / (denominator + self.smooth)\n",
        "\n",
        "        # Average over classes and batch\n",
        "        return 1 - dice_scores.mean()\n",
        "\n",
        "class CombinedLoss(nn.Module):\n",
        "    \"\"\"Combined Dice and weighted Cross-Entropy loss with focus on cancer classes\"\"\"\n",
        "    def __init__(self, smooth=1e-5, ce_weight=0.5, background_weight=0.1):\n",
        "        super(CombinedLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "        self.ce_weight = ce_weight\n",
        "        self.background_weight = background_weight\n",
        "        self.dice_loss = DiceLoss(smooth=smooth)\n",
        "\n",
        "    def forward(self, predictions, targets):\n",
        "        # Calculate class weights with reduced background weight\n",
        "        n_classes = predictions.shape[1]\n",
        "        class_counts = torch.bincount(targets.flatten(), minlength=n_classes).float()\n",
        "        total_pixels = class_counts.sum()\n",
        "        \n",
        "        # Modify weights to focus on cancer classes\n",
        "        class_weights = torch.zeros_like(class_counts)\n",
        "        class_weights[0] = self.background_weight  # Background class\n",
        "        class_weights[1:] = (1.0 - self.background_weight) / (n_classes - 1)  # Cancer classes\n",
        "        \n",
        "        # Scale weights by inverse frequency within cancer classes\n",
        "        cancer_counts = class_counts[1:]  # Counts for cancer classes\n",
        "        if cancer_counts.sum() > 0:  # Avoid division by zero\n",
        "            cancer_weights = total_pixels / (cancer_counts * n_classes + self.smooth)\n",
        "            cancer_weights = cancer_weights / cancer_weights.sum()  # Normalize\n",
        "            class_weights[1:] *= cancer_weights\n",
        "        \n",
        "        class_weights = class_weights.to(predictions.device)\n",
        "\n",
        "        # Dice Loss (focusing on cancer classes)\n",
        "        dice_loss = self.dice_loss(predictions, targets)\n",
        "\n",
        "        # Weighted Cross Entropy Loss\n",
        "        ce_loss = F.cross_entropy(predictions, targets, weight=class_weights)\n",
        "\n",
        "        # Combine losses\n",
        "        return dice_loss + self.ce_weight * ce_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 4ï¸âƒ£ Dataset and Model Architecture\n",
        "\n",
        "## ðŸ“Š Dataset Implementation\n",
        "We'll create a custom PyTorch Dataset class that:\n",
        "- Loads and preprocesses 3D medical images\n",
        "- Handles data normalization and augmentation\n",
        "- Manages batch creation for training\n",
        "\n",
        "## ðŸ—ï¸ Model Architecture\n",
        "Our 3D U-Net implementation includes:\n",
        "- Encoder path with increasing feature channels\n",
        "- Decoder path with skip connections\n",
        "- Advanced features:\n",
        "  - Batch normalization for stable training\n",
        "  - Residual connections for better gradient flow\n",
        "  - Dropout for regularization\n",
        "  - Squeeze-and-Excitation blocks for channel attention\n",
        "\n",
        "Let's implement these components:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class OvarianCancerDataset(Dataset):\n",
        "    \"\"\"Dataset class for 2D slice-based ovarian cancer segmentation\"\"\"\n",
        "    def __init__(self, ct_files, seg_files, target_size=128, is_train=True, window=4000, level=400):\n",
        "        self.ct_files = ct_files\n",
        "        self.seg_files = seg_files\n",
        "        self.target_size = target_size\n",
        "        self.is_train = is_train\n",
        "        self.window = window\n",
        "        self.level = level\n",
        "        \n",
        "        # Store slice indices with disease for each volume\n",
        "        self.slice_indices = []\n",
        "        self._find_disease_slices()\n",
        "        \n",
        "    def _find_disease_slices(self):\n",
        "        \"\"\"Find slices containing disease in each volume\"\"\"\n",
        "        for ct_file, seg_file in zip(self.ct_files, self.seg_files):\n",
        "            ct_path = os.path.join('Data_Subsample/CT', ct_file)\n",
        "            seg_path = os.path.join('Data_Subsample/Segmentation', seg_file)\n",
        "            \n",
        "            # Load segmentation volume\n",
        "            seg_vol = nib.load(seg_path).get_fdata()\n",
        "            \n",
        "            # Find slices with disease (class 1 or 2)\n",
        "            disease_slices = []\n",
        "            for z in range(seg_vol.shape[2]):\n",
        "                if np.any(seg_vol[:,:,z] > 0):  # Any non-background pixels\n",
        "                    disease_slices.append(z)\n",
        "            \n",
        "            if len(disease_slices) > 0:\n",
        "                # Add some context slices before and after disease\n",
        "                min_z = max(0, min(disease_slices) - 5)\n",
        "                max_z = min(seg_vol.shape[2], max(disease_slices) + 5)\n",
        "                disease_slices = list(range(min_z, max_z))\n",
        "                \n",
        "                self.slice_indices.extend([(ct_file, seg_file, z) for z in disease_slices])\n",
        "\n",
        "    def apply_window_level(self, ct_slice):\n",
        "        \"\"\"Apply window/level adjustment to CT slice\"\"\"\n",
        "        window = self.window\n",
        "        level = self.level\n",
        "        min_value = level - window/2\n",
        "        max_value = level + window/2\n",
        "        ct_slice = np.clip(ct_slice, min_value, max_value)\n",
        "        ct_slice = (ct_slice - min_value) / (max_value - min_value)\n",
        "        return ct_slice\n",
        "\n",
        "    def augment_slice(self, ct_slice, seg_slice):\n",
        "        \"\"\"Apply 2D augmentations\"\"\"\n",
        "        if not self.is_train:\n",
        "            return ct_slice, seg_slice\n",
        "\n",
        "        # Make copies\n",
        "        ct_slice = ct_slice.copy()\n",
        "        seg_slice = seg_slice.copy()\n",
        "\n",
        "        # Random flip\n",
        "        if np.random.random() > 0.5:\n",
        "            ct_slice = np.flip(ct_slice, axis=0)\n",
        "            seg_slice = np.flip(seg_slice, axis=0)\n",
        "        if np.random.random() > 0.5:\n",
        "            ct_slice = np.flip(ct_slice, axis=1)\n",
        "            seg_slice = np.flip(seg_slice, axis=1)\n",
        "\n",
        "        # Random rotation\n",
        "        if np.random.random() > 0.5:\n",
        "            angle = np.random.uniform(-15, 15)\n",
        "            ct_slice = transform.rotate(ct_slice, angle, mode='reflect', preserve_range=True)\n",
        "            seg_slice = transform.rotate(seg_slice, angle, mode='reflect', order=0, preserve_range=True)\n",
        "\n",
        "        return ct_slice, seg_slice\n",
        "\n",
        "    def preprocess_slice(self, ct_slice, seg_slice):\n",
        "        \"\"\"Preprocess a single slice pair\"\"\"\n",
        "        # Resize\n",
        "        if ct_slice.shape != (self.target_size, self.target_size):\n",
        "            ct_slice = transform.resize(ct_slice, \n",
        "                                     (self.target_size, self.target_size),\n",
        "                                     order=1,\n",
        "                                     preserve_range=True,\n",
        "                                     anti_aliasing=True)\n",
        "            seg_slice = transform.resize(seg_slice,\n",
        "                                      (self.target_size, self.target_size),\n",
        "                                      order=0,\n",
        "                                      preserve_range=True,\n",
        "                                      anti_aliasing=False)\n",
        "\n",
        "        # Apply window/level\n",
        "        ct_slice = self.apply_window_level(ct_slice)\n",
        "\n",
        "        # Apply augmentation\n",
        "        if self.is_train:\n",
        "            ct_slice, seg_slice = self.augment_slice(ct_slice, seg_slice)\n",
        "\n",
        "        # Ensure segmentation values are integers\n",
        "        seg_slice = np.round(seg_slice).astype(np.int64)\n",
        "\n",
        "        return ct_slice, seg_slice\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.slice_indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ct_file, seg_file, z_idx = self.slice_indices[idx]\n",
        "        \n",
        "        # Load volumes\n",
        "        ct_path = os.path.join('Data_Subsample/CT', ct_file)\n",
        "        seg_path = os.path.join('Data_Subsample/Segmentation', seg_file)\n",
        "        \n",
        "        ct_vol = nib.load(ct_path).get_fdata()\n",
        "        seg_vol = nib.load(seg_path).get_fdata()\n",
        "        \n",
        "        # Extract and preprocess slices\n",
        "        ct_slice = ct_vol[:,:,z_idx]\n",
        "        seg_slice = seg_vol[:,:,z_idx]\n",
        "        \n",
        "        ct_slice, seg_slice = self.preprocess_slice(ct_slice, seg_slice)\n",
        "        \n",
        "        # Ensure arrays are contiguous\n",
        "        ct_slice = np.ascontiguousarray(ct_slice)\n",
        "        seg_slice = np.ascontiguousarray(seg_slice)\n",
        "        \n",
        "        # Convert to tensors\n",
        "        ct_slice = torch.FloatTensor(ct_slice).unsqueeze(0)  # Add channel dimension\n",
        "        seg_slice = torch.LongTensor(seg_slice)\n",
        "        \n",
        "        return ct_slice, seg_slice\n",
        "\n",
        "# Split data into training and validation sets\n",
        "train_ct, val_ct, train_seg, val_seg = train_test_split(\n",
        "    ct_files, seg_files, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = OvarianCancerDataset(train_ct, train_seg)\n",
        "val_dataset = OvarianCancerDataset(val_ct, val_seg)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "\n",
        "# Create dataloaders with larger batch sizes for 2D\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, \n",
        "    batch_size=32,  # Increased batch size for 2D slices\n",
        "    shuffle=True,\n",
        "    num_workers=4 if torch.cuda.is_available() else 0,  # Use multiple workers for faster loading\n",
        "    pin_memory=True if torch.cuda.is_available() else False,\n",
        "    drop_last=True  # Drop incomplete batches for stable training\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset, \n",
        "    batch_size=32,  # Same batch size for consistent validation\n",
        "    shuffle=False,\n",
        "    num_workers=4 if torch.cuda.is_available() else 0,\n",
        "    pin_memory=True if torch.cuda.is_available() else False,\n",
        "    drop_last=False  # Keep all validation samples\n",
        ")\n",
        "\n",
        "print(f'Training samples: {len(train_dataset)}')\n",
        "print(f'Validation samples: {len(val_dataset)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SEBlock(nn.Module):\n",
        "    \"\"\"Squeeze-and-Excitation block for channel attention\"\"\"\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super().__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channels, channels // reduction),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channels // reduction, channels),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"Enhanced double convolution block with SE attention\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.se = SEBlock(out_channels)\n",
        "        self.residual = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        main = self.double_conv(x)\n",
        "        main = self.se(main)\n",
        "        residual = self.residual(x)\n",
        "        return F.relu(main + residual)\n",
        "\n",
        "class UNet2D(nn.Module):\n",
        "    \"\"\"Enhanced 2D U-Net with SE attention, residual connections, and deep supervision\"\"\"\n",
        "    def __init__(self, in_channels=1, out_channels=3, features=[32, 64, 128, 256]):\n",
        "        super(UNet2D, self).__init__()\n",
        "        self.encoder = nn.ModuleList()\n",
        "        self.decoder = nn.ModuleList()\n",
        "        self.deep_supervision = nn.ModuleList()\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Encoder\n",
        "        in_channels_temp = in_channels\n",
        "        for feature in features:\n",
        "            self.encoder.append(DoubleConv(in_channels_temp, feature))\n",
        "            in_channels_temp = feature\n",
        "\n",
        "        # Decoder with deep supervision\n",
        "        for i, feature in enumerate(reversed(features[:-1])):\n",
        "            # Upsampling\n",
        "            self.decoder.append(\n",
        "                nn.Sequential(\n",
        "                    nn.ConvTranspose2d(\n",
        "                        features[features.index(feature)+1],\n",
        "                        feature,\n",
        "                        kernel_size=2,\n",
        "                        stride=2\n",
        "                    ),\n",
        "                    nn.BatchNorm2d(feature),\n",
        "                    nn.ReLU(inplace=True)\n",
        "                )\n",
        "            )\n",
        "            # Double conv after concatenation\n",
        "            self.decoder.append(DoubleConv(feature * 2, feature))\n",
        "            \n",
        "            # Deep supervision outputs\n",
        "            self.deep_supervision.append(\n",
        "                nn.Conv2d(feature, out_channels, kernel_size=1)\n",
        "            )\n",
        "\n",
        "        self.bottleneck = DoubleConv(features[-2], features[-1])\n",
        "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
        "\n",
        "        # Advanced regularization\n",
        "        self.dropout = nn.Dropout2d(p=0.3)\n",
        "        self.spatial_dropout = nn.Dropout2d(p=0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip_connections = []\n",
        "        deep_outputs = []\n",
        "\n",
        "        # Encoder\n",
        "        for encoder in self.encoder[:-1]:\n",
        "            x = encoder(x)\n",
        "            x = self.spatial_dropout(x)  # Spatial dropout for feature map augmentation\n",
        "            skip_connections.append(x)\n",
        "            x = self.pool(x)\n",
        "            x = self.dropout(x)\n",
        "\n",
        "        x = self.bottleneck(x)\n",
        "\n",
        "        # Decoder with deep supervision\n",
        "        skip_connections = skip_connections[::-1]\n",
        "        for idx in range(0, len(self.decoder), 2):\n",
        "            x = self.decoder[idx](x)\n",
        "            skip = skip_connections[idx//2]\n",
        "\n",
        "            # Handle different sizes\n",
        "            if x.shape != skip.shape:\n",
        "                x = F.interpolate(x, size=skip.shape[2:])\n",
        "\n",
        "            concat_skip = torch.cat((skip, x), dim=1)\n",
        "            x = self.decoder[idx+1](concat_skip)\n",
        "            x = self.dropout(x)\n",
        "\n",
        "            # Deep supervision output\n",
        "            deep_out = self.deep_supervision[idx//2](x)\n",
        "            deep_outputs.append(deep_out)\n",
        "\n",
        "        # Final output\n",
        "        final_out = self.final_conv(x)\n",
        "        \n",
        "        if self.training:\n",
        "            # During training, return main output and deep supervision outputs\n",
        "            return final_out, deep_outputs\n",
        "        else:\n",
        "            # During inference, return only the main output\n",
        "            return final_out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 5ï¸âƒ£ Training and Evaluation\n",
        "\n",
        "## ðŸƒâ€â™‚ï¸ Training Process\n",
        "Our training pipeline includes:\n",
        "- Batch-wise training with GPU acceleration\n",
        "- Learning rate scheduling with ReduceLROnPlateau\n",
        "- Early stopping to prevent overfitting\n",
        "- Model checkpointing to save best weights\n",
        "- Memory optimization with periodic cache clearing\n",
        "\n",
        "## ðŸ“ˆ Evaluation Metrics\n",
        "We'll monitor:\n",
        "- Dice coefficient per class\n",
        "- Overall segmentation accuracy\n",
        "- Class-wise precision and recall\n",
        "- Training and validation loss curves\n",
        "\n",
        "## ðŸ” Visualization\n",
        "During and after training, we'll visualize:\n",
        "- Sample predictions on validation data\n",
        "- Training progress and learning curves\n",
        "- Segmentation overlays on CT slices\n",
        "\n",
        "Let's implement the training loop and evaluation functions:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to visualize predictions\n",
        "def visualize_predictions(model, data_loader, num_samples=3):\n",
        "    \"\"\"Visualize model predictions alongside ground truth\"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Get a batch of data\n",
        "        data, target = next(iter(data_loader))\n",
        "        if torch.cuda.is_available():\n",
        "            data = data.cuda()\n",
        "            target = target.cuda()\n",
        "        \n",
        "        # Make predictions\n",
        "        output = model(data)\n",
        "        pred = F.softmax(output, dim=1)\n",
        "        pred = torch.argmax(pred, dim=1)\n",
        "        \n",
        "        # Move tensors to CPU for visualization\n",
        "        data = data.cpu()\n",
        "        target = target.cpu()\n",
        "        pred = pred.cpu()\n",
        "        \n",
        "        # Create a figure\n",
        "        fig, axes = plt.subplots(num_samples, 3, figsize=(12, 4*num_samples))\n",
        "        \n",
        "        for i in range(num_samples):\n",
        "            # Original CT slice\n",
        "            axes[i,0].imshow(data[i,0], cmap='gray')\n",
        "            axes[i,0].set_title('Input CT')\n",
        "            axes[i,0].axis('off')\n",
        "            \n",
        "            # Ground truth\n",
        "            axes[i,1].imshow(target[i], cmap='tab10')\n",
        "            axes[i,1].set_title('Ground Truth')\n",
        "            axes[i,1].axis('off')\n",
        "            \n",
        "            # Prediction\n",
        "            axes[i,2].imshow(pred[i], cmap='tab10')\n",
        "            axes[i,2].set_title('Prediction')\n",
        "            axes[i,2].axis('off')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Initialize 2D model and move to GPU if available\n",
        "model = UNet2D(in_channels=1, out_channels=3, features=[16, 32, 64, 128])  # Reduced feature maps\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "print(f\"Model architecture:\\n{model}\")\n",
        "\n",
        "# Training setup with focus on cancer classes\n",
        "criterion = CombinedLoss(\n",
        "    ce_weight=0.7,  # Balance between Dice and CE\n",
        "    background_weight=0.1,  # Reduce focus on background class\n",
        "    smooth=1e-5\n",
        ")\n",
        "\n",
        "# Optimizer with gradient clipping\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=1e-3,  # Slightly higher learning rate for faster convergence\n",
        "    weight_decay=0.01,\n",
        "    amsgrad=True\n",
        ")\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr=1e-3,\n",
        "    epochs=20,  # Reduced epochs\n",
        "    steps_per_epoch=len(train_loader),\n",
        "    pct_start=0.3,\n",
        "    div_factor=10,\n",
        "    final_div_factor=1000\n",
        ")\n",
        "\n",
        "# Training loop with improved monitoring\n",
        "n_epochs = 20  # Reduced epochs\n",
        "best_val_dice = 0.0\n",
        "patience = 5  # Reduced patience\n",
        "patience_counter = 0\n",
        "history = {'train_loss': [], 'val_loss': [], 'val_dice': [], 'lr': []}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization function for training progress\n",
        "def plot_training_history(history):\n",
        "    \"\"\"Plot training metrics over time\"\"\"\n",
        "    epochs = range(1, len(history['train_loss']) + 1)\n",
        "    \n",
        "    plt.figure(figsize=(12, 4))\n",
        "    \n",
        "    # Plot losses\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, history['train_loss'], 'b-', label='Training Loss')\n",
        "    plt.plot(epochs, history['val_loss'], 'r-', label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    \n",
        "    # Plot Dice score and learning rate\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, history['val_dice'], 'g-', label='Validation Dice')\n",
        "    plt.plot(epochs, history['lr'], 'y-', label='Learning Rate')\n",
        "    plt.title('Validation Dice Score and Learning Rate')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Value')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_epoch(model, loader, optimizer, criterion, deep_weight=0.5):\n",
        "    \"\"\"Train the model for one epoch with deep supervision\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    num_batches = len(loader)\n",
        "    \n",
        "    # Progress tracking\n",
        "    processed_batches = 0\n",
        "    report_interval = max(1, num_batches // 10)  # Report roughly 10 times per epoch\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(loader):\n",
        "        # Move data to GPU if available\n",
        "        if torch.cuda.is_available():\n",
        "            data = data.cuda()\n",
        "            target = target.cuda()\n",
        "\n",
        "        # Clear gradients\n",
        "        optimizer.zero_grad(set_to_none=True)  # More efficient than zero_grad()\n",
        "\n",
        "        # Forward pass with deep supervision\n",
        "        main_output, deep_outputs = model(data)\n",
        "        \n",
        "        # Calculate main loss\n",
        "        main_loss = criterion(main_output, target)\n",
        "        \n",
        "        # Calculate deep supervision losses\n",
        "        deep_loss = 0\n",
        "        for deep_out in deep_outputs:\n",
        "            # Resize deep supervision output to match target size if needed\n",
        "            if deep_out.shape[2:] != target.shape[1:]:  # Compare with target's spatial dimensions\n",
        "                deep_out = F.interpolate(deep_out, size=target.shape[1:], mode='bilinear', align_corners=False)\n",
        "            deep_loss += criterion(deep_out, target)\n",
        "        \n",
        "        # Combine losses\n",
        "        loss = main_loss + deep_weight * (deep_loss / len(deep_outputs))\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        \n",
        "        optimizer.step()\n",
        "\n",
        "        # Update metrics\n",
        "        total_loss += loss.item()\n",
        "        processed_batches += 1\n",
        "\n",
        "        # Print progress\n",
        "        if (batch_idx + 1) % report_interval == 0:\n",
        "            avg_loss = total_loss / processed_batches\n",
        "            progress = (batch_idx + 1) / num_batches * 100\n",
        "            print(f'Progress: {progress:.1f}%, Average Loss: {avg_loss:.4f}')\n",
        "\n",
        "    return total_loss / num_batches\n",
        "\n",
        "def validate(model, loader, criterion):\n",
        "    \"\"\"Validate the model\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    class_dice_scores = {i: [] for i in range(3)}  # Track per-class Dice scores\n",
        "    num_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in loader:\n",
        "            # Move data to GPU if available\n",
        "            if torch.cuda.is_available():\n",
        "                data = data.cuda()\n",
        "                target = target.cuda()\n",
        "            \n",
        "            # Model returns only main output during validation\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            \n",
        "            # Calculate per-class Dice scores\n",
        "            pred = F.softmax(output, dim=1)\n",
        "            pred = torch.argmax(pred, dim=1)\n",
        "            \n",
        "            # Calculate batch Dice scores for each class\n",
        "            for i in range(3):  # 3 classes\n",
        "                class_pred = pred == i\n",
        "                class_target = target == i\n",
        "                # Only calculate Dice if the class is present in the target\n",
        "                if class_target.sum() > 0 or class_pred.sum() > 0:\n",
        "                    dice = calculate_dice_score(class_pred, class_target)\n",
        "                    class_dice_scores[i].append(dice)\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "    # Calculate average Dice scores\n",
        "    class_avg_dice = {i: np.mean(scores) if scores else 0.0 \n",
        "                     for i, scores in class_dice_scores.items()}\n",
        "    \n",
        "    # Print per-class Dice scores\n",
        "    print(\"\\nValidation Dice scores:\")\n",
        "    print(f\"Background: {class_avg_dice[0]:.4f}\")\n",
        "    print(f\"Primary cancer: {class_avg_dice[1]:.4f}\")\n",
        "    print(f\"Metastatic: {class_avg_dice[2]:.4f}\")\n",
        "    \n",
        "    # Overall Dice score (weighted average, focusing on cancer classes)\n",
        "    avg_dice = (class_avg_dice[1] + class_avg_dice[2]) / 2\n",
        "    \n",
        "    return total_loss / num_batches, avg_dice\n",
        "\n",
        "def calculate_dice_score(pred, target):\n",
        "    \"\"\"Calculate Dice score for binary masks\"\"\"\n",
        "    intersection = (pred & target).sum().float()\n",
        "    union = pred.sum() + target.sum()\n",
        "    if union == 0:\n",
        "        return 1.0  # Define empty as perfect match\n",
        "    return (2.0 * intersection / union).item()\n",
        "\n",
        "def predict_slice(model, ct_slice):\n",
        "    \"\"\"Generate predictions for a single slice\"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        if torch.cuda.is_available():\n",
        "            ct_slice = ct_slice.cuda()\n",
        "        pred = model(ct_slice.unsqueeze(0))\n",
        "        pred = F.softmax(pred, dim=1)\n",
        "        pred = torch.argmax(pred, dim=1)\n",
        "    return pred[0].cpu().numpy()\n",
        "\n",
        "\n",
        "# Training setup with focus on cancer classes\n",
        "criterion = CombinedLoss(\n",
        "    ce_weight=0.7,  # Balance between Dice and CE\n",
        "    background_weight=0.1,  # Reduce focus on background class\n",
        "    smooth=1e-5\n",
        ")\n",
        "\n",
        "# Optimizer with gradient clipping\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=1e-3,\n",
        "    weight_decay=0.01,\n",
        "    amsgrad=True  # Use AMSGrad variant\n",
        ")\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr=1e-3,\n",
        "    epochs=50,\n",
        "    steps_per_epoch=len(train_loader),\n",
        "    pct_start=0.3,  # Warm-up period\n",
        "    div_factor=25,  # Initial lr = max_lr/25\n",
        "    final_div_factor=1000,  # Min lr = initial_lr/1000\n",
        ")\n",
        "\n",
        "# Training loop with improved monitoring\n",
        "n_epochs = 50  # Increased epochs\n",
        "best_val_dice = 0.0  # Track best Dice score instead of loss\n",
        "patience = 10  # Increased patience\n",
        "patience_counter = 0\n",
        "history = {'train_loss': [], 'val_loss': [], 'val_dice': [], 'lr': []}\n",
        "\n",
        "print(\"Starting training...\")\n",
        "for epoch in range(n_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{n_epochs}\")\n",
        "    \n",
        "    # Training phase with deep supervision\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, criterion, deep_weight=0.5)\n",
        "    print(f\"Training Loss: {train_loss:.4f}\")\n",
        "    \n",
        "    # Validation phase\n",
        "    val_loss, val_dice = validate(model, val_loader, criterion)\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, Validation Dice: {val_dice:.4f}\")\n",
        "    \n",
        "    # Learning rate scheduling\n",
        "    scheduler.step()\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    print(f\"Current learning rate: {current_lr:.2e}\")\n",
        "    \n",
        "    # Update history\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_dice'].append(val_dice)\n",
        "    history['lr'].append(current_lr)\n",
        "    \n",
        "    # Plot training progress\n",
        "    plot_training_history(history)\n",
        "    \n",
        "    # Visualize predictions every 5 epochs\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(\"\\nTraining set predictions:\")\n",
        "        visualize_predictions(model, train_loader)\n",
        "        print(\"\\nValidation set predictions:\")\n",
        "        visualize_predictions(model, val_loader)\n",
        "    \n",
        "    # Model checkpointing based on Dice score\n",
        "    if val_dice > best_val_dice:\n",
        "        best_val_dice = val_dice\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'best_dice': best_val_dice,\n",
        "            'history': history\n",
        "        }, 'best_model.pth')\n",
        "        patience_counter = 0\n",
        "        print(f\"Saved new best model with Dice score: {best_val_dice:.4f}!\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "    \n",
        "    # Early stopping\n",
        "    if patience_counter >= patience:\n",
        "        print(f\"\\nEarly stopping triggered after {epoch+1} epochs\")\n",
        "        print(f\"Best validation Dice score: {best_val_dice:.4f}\")\n",
        "        break\n",
        "    \n",
        "    # Clear GPU memory\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "# After training, visualize final predictions on test set\n",
        "print(\"\\nFinal predictions on validation set:\")\n",
        "visualize_predictions(model, val_loader, num_samples=5)  # Show more samples for final evaluation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 6ï¸âƒ£ Discussion and Future Work\n",
        "\n",
        "## ðŸ” Technical Analysis\n",
        "Consider and discuss the following aspects of your implementation:\n",
        "\n",
        "### Data Challenges\n",
        "- What difficulties did you encounter with the medical imaging data?\n",
        "- How effective was your preprocessing pipeline?\n",
        "- What additional data augmentation techniques could be beneficial?\n",
        "\n",
        "### Model Performance\n",
        "- How well did the model segment different tissue types?\n",
        "- What were the main sources of errors?\n",
        "- How could the architecture be improved?\n",
        "\n",
        "## ðŸ¥ Clinical Impact\n",
        "Reflect on the clinical applications:\n",
        "\n",
        "### Current Capabilities\n",
        "- How reliable is the model for clinical use?\n",
        "- What are the limitations of the current implementation?\n",
        "- How does it compare to human expert performance?\n",
        "\n",
        "### Future Improvements\n",
        "- What additional validation would be needed for clinical deployment?\n",
        "- How could the model be integrated into clinical workflows?\n",
        "- What safety measures should be implemented?\n",
        "\n",
        "## ðŸš€ Next Steps\n",
        "Consider these potential improvements:\n",
        "\n",
        "### Technical Enhancements\n",
        "- Implement additional data augmentation techniques\n",
        "- Experiment with different model architectures\n",
        "- Add uncertainty quantification\n",
        "- Optimize for inference speed\n",
        "\n",
        "### Clinical Integration\n",
        "- Develop a user-friendly interface\n",
        "- Add reporting and visualization tools\n",
        "- Implement quality assurance measures\n",
        "- Design clinical validation studies\n",
        "\n",
        "Write your answers and reflections below:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1Jz7yec3bzO"
      },
      "source": [
        "# 9. Discussion Questions\n",
        "\n",
        "Please answer the following questions based on your implementation and results:\n",
        "\n",
        "1. **Data Analysis**\n",
        "   - What challenges did you encounter with the medical imaging data?\n",
        "   - How did you handle class imbalance?\n",
        "\n",
        "2. **Model Performance**\n",
        "   - How well did the model perform on different classes?\n",
        "   - What were the main sources of error?\n",
        "\n",
        "3. **Clinical Relevance**\n",
        "   - How might this model be useful in a clinical setting?\n",
        "   - What additional validation would be needed?\n",
        "\n",
        "4. **Improvements**\n",
        "   - What modifications could improve the model's performance?\n",
        "   - How could the preprocessing pipeline be enhanced?\n",
        "\n",
        "Write your answers below:\n",
        "\n",
        "1. Data Analysis:\n",
        "   > Your answer here\n",
        "\n",
        "2. Model Performance:\n",
        "   > Your answer here\n",
        "\n",
        "3. Clinical Relevance:\n",
        "   > Your answer here\n",
        "\n",
        "4. Improvements:\n",
        "   > Your answer here\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
