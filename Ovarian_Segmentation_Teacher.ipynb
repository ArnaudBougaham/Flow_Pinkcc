{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aq41EyRt3bzG",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "# üî¨ Ovarian Cancer Segmentation Lab\n",
        "\n",
        "Welcome to this comprehensive lab on medical image segmentation for ovarian cancer detection! In this lab, you'll work with volumetric CT scan data to develop an advanced deep learning solution for automated cancer tissue identification.\n",
        "\n",
        "## üìã Task Overview\n",
        "Your goal is to develop a 3D U-Net model that can accurately segment CT volumes into three distinct classes:\n",
        "- **Class 0**: Background tissue\n",
        "- **Class 1**: Primary ovarian cancer\n",
        "- **Class 2**: Metastatic tissue\n",
        "\n",
        "## üéØ Learning Objectives\n",
        "By completing this lab, you will:\n",
        "- Master working with medical imaging data in NIfTI format\n",
        "- Implement and understand the 3D U-Net architecture\n",
        "- Learn effective training strategies for medical image segmentation\n",
        "- Develop skills in evaluating and validating medical imaging models\n",
        "- Gain practical experience with real-world medical data\n",
        "\n",
        "## üîç Clinical Relevance\n",
        "Accurate segmentation of ovarian cancer tissues is crucial for:\n",
        "- Early detection and diagnosis\n",
        "- Treatment planning and monitoring\n",
        "- Assessment of disease progression\n",
        "- Research and clinical trials\n",
        "\n",
        "Let's dive in and build a solution that could make a real difference in healthcare! üöÄ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d08DKLq3bzH"
      },
      "source": [
        "# 1Ô∏è‚É£ Environment Setup and Dependencies\n",
        "\n",
        "Before we begin our implementation, let's set up our development environment with all necessary packages and configurations.\n",
        "\n",
        "## üì¶ Required Packages\n",
        "We'll be using the following key libraries:\n",
        "- **PyTorch**: For deep learning model implementation\n",
        "- **NiBabel**: For handling medical imaging data in NIfTI format\n",
        "- **scikit-image**: For image processing and transformations\n",
        "- **NumPy**: For numerical computations\n",
        "- **Matplotlib**: For visualization\n",
        "\n",
        "## üñ•Ô∏è Hardware Requirements\n",
        "- GPU with CUDA support (recommended)\n",
        "- Sufficient RAM for 3D volume processing\n",
        "- Adequate storage for medical imaging data\n",
        "\n",
        "## ‚öôÔ∏è Configuration\n",
        "We'll set up:\n",
        "- CUDA device if available\n",
        "- Random seeds for reproducibility\n",
        "- Memory optimization settings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install numpy --quiet\n",
        "!pip install scipy --quiet\n",
        "!pip install scikit-learn --quiet\n",
        "!pip install scikit-image nibabel gdown torch torchvision --quiet\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nibabel as nib\n",
        "from skimage import transform\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Set up GPU if available\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"WARNING: CUDA is not available. Please make sure to enable GPU in Runtime > Change runtime type\")\n",
        "    print(\"Current device: CPU\")\n",
        "else:\n",
        "    # Set default tensor type to CUDA\n",
        "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "    device = torch.device('cuda')\n",
        "    print(f\"Using device: {device}\")\n",
        "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Available memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 2Ô∏è‚É£ Data Acquisition and Preprocessing\n",
        "\n",
        "## üì• Dataset Download\n",
        "First, we'll download our dataset containing CT scans and their corresponding segmentation masks. The data is stored in NIfTI format (`.nii.gz`), which is commonly used for medical imaging.\n",
        "\n",
        "## üóÇÔ∏è Data Organization\n",
        "The dataset is organized into two main directories:\n",
        "- `Data_Subsample/CT/`: Contains the CT scan volumes\n",
        "- `Data_Subsample/Segmentation/`: Contains the corresponding segmentation masks\n",
        "\n",
        "## üíæ Data Loading\n",
        "Let's download and extract the dataset, then verify our data structure:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download and extract dataset\n",
        "file_id = '1Wo4h6ZVIFygVvqd68ApwWIdPQk3l7gkO'\n",
        "output = 'Data_Subsample.zip'\n",
        "\n",
        "if not os.path.exists('Data_Subsample.zip'):\n",
        "    import subprocess\n",
        "    subprocess.run(['gdown', '--id', file_id, '-O', output])\n",
        "\n",
        "# Extract data if not already extracted\n",
        "if not os.path.exists('Data_Subsample'):\n",
        "    import zipfile\n",
        "    with zipfile.ZipFile(output, 'r') as zip_ref:\n",
        "        zip_ref.extractall('.')\n",
        "\n",
        "# List available files\n",
        "ct_files = sorted([f for f in os.listdir('Data_Subsample/CT') if f.endswith('.nii.gz')])\n",
        "seg_files = sorted([f for f in os.listdir('Data_Subsample/Segmentation') if f.endswith('.nii.gz')])\n",
        "\n",
        "print(f'Number of CT volumes: {len(ct_files)}')\n",
        "print(f'Number of segmentation masks: {len(seg_files)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 3Ô∏è‚É£ Loss Functions and Metrics\n",
        "\n",
        "For medical image segmentation, choosing appropriate loss functions is crucial. We'll implement two key components:\n",
        "\n",
        "## üéØ Dice Loss\n",
        "The Dice coefficient (also known as F1 score) is particularly useful for segmentation tasks because it:\n",
        "- Handles class imbalance well\n",
        "- Focuses on overlap between predictions and ground truth\n",
        "- Ranges from 0 (no overlap) to 1 (perfect overlap)\n",
        "\n",
        "## üîÑ Combined Loss\n",
        "We'll combine Dice Loss with weighted Cross-Entropy to:\n",
        "- Balance between pixel-wise and region-based segmentation quality\n",
        "- Handle class imbalance through dynamic class weights\n",
        "- Provide smoother gradients during training\n",
        "\n",
        "Let's implement these loss functions:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DiceLoss(nn.Module):\n",
        "    \"\"\"Dice Loss for multi-class 3D segmentation\"\"\"\n",
        "    def __init__(self, smooth=1e-5):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def forward(self, predictions, targets):\n",
        "        # predictions shape: (batch_size, n_classes, d1, d2, d3)\n",
        "        # targets shape: (batch_size, d1, d2, d3)\n",
        "\n",
        "        # Convert predictions to probabilities\n",
        "        predictions = F.softmax(predictions, dim=1)\n",
        "\n",
        "        # One-hot encode targets\n",
        "        n_classes = predictions.shape[1]\n",
        "        one_hot_targets = F.one_hot(targets, n_classes).permute(0, 4, 1, 2, 3).float()\n",
        "\n",
        "        # Calculate Dice score for each class\n",
        "        numerator = 2 * (predictions * one_hot_targets).sum(dim=(2, 3, 4))\n",
        "        denominator = predictions.sum(dim=(2, 3, 4)) + one_hot_targets.sum(dim=(2, 3, 4))\n",
        "        dice_scores = (numerator + self.smooth) / (denominator + self.smooth)\n",
        "\n",
        "        # Average over classes and batch\n",
        "        return 1 - dice_scores.mean()\n",
        "\n",
        "class CombinedLoss(nn.Module):\n",
        "    \"\"\"Combined Dice and weighted Cross-Entropy loss\"\"\"\n",
        "    def __init__(self, smooth=1e-5, ce_weight=0.5):\n",
        "        super(CombinedLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "        self.ce_weight = ce_weight\n",
        "        self.dice_loss = DiceLoss(smooth=smooth)\n",
        "\n",
        "    def forward(self, predictions, targets):\n",
        "        # Calculate class weights based on inverse frequency\n",
        "        n_classes = predictions.shape[1]\n",
        "        class_counts = torch.bincount(targets.flatten(), minlength=n_classes).float()\n",
        "        total_pixels = class_counts.sum()\n",
        "        class_weights = total_pixels / (class_counts * n_classes + self.smooth)\n",
        "        class_weights = class_weights.to(predictions.device)\n",
        "\n",
        "        # Dice Loss\n",
        "        dice_loss = self.dice_loss(predictions, targets)\n",
        "\n",
        "        # Weighted Cross Entropy Loss\n",
        "        ce_loss = F.cross_entropy(predictions, targets, weight=class_weights)\n",
        "\n",
        "        # Combine losses\n",
        "        return dice_loss + self.ce_weight * ce_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 4Ô∏è‚É£ Dataset and Model Architecture\n",
        "\n",
        "## üìä Dataset Implementation\n",
        "We'll create a custom PyTorch Dataset class that:\n",
        "- Loads and preprocesses 3D medical images\n",
        "- Handles data normalization and augmentation\n",
        "- Manages batch creation for training\n",
        "\n",
        "## üèóÔ∏è Model Architecture\n",
        "Our 3D U-Net implementation includes:\n",
        "- Encoder path with increasing feature channels\n",
        "- Decoder path with skip connections\n",
        "- Advanced features:\n",
        "  - Batch normalization for stable training\n",
        "  - Residual connections for better gradient flow\n",
        "  - Dropout for regularization\n",
        "  - Squeeze-and-Excitation blocks for channel attention\n",
        "\n",
        "Let's implement these components:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class OvarianCancerDataset(Dataset):\n",
        "    \"\"\"Dataset class for 3D ovarian cancer segmentation\"\"\"\n",
        "    def __init__(self, ct_files, seg_files, target_shape=(64, 64, 64)):\n",
        "        self.ct_files = ct_files\n",
        "        self.seg_files = seg_files\n",
        "        self.target_shape = target_shape\n",
        "\n",
        "    def normalize_volume(self, volume):\n",
        "        \"\"\"Normalize volume to [0,1] range\"\"\"\n",
        "        min_val = np.min(volume)\n",
        "        max_val = np.max(volume)\n",
        "        if max_val - min_val == 0:\n",
        "            return volume\n",
        "        return (volume - min_val) / (max_val - min_val)\n",
        "\n",
        "    def load_volume(self, file_path):\n",
        "        \"\"\"Load a NIfTI volume and return its data\"\"\"\n",
        "        return nib.load(file_path).get_fdata()\n",
        "\n",
        "    def preprocess_volume(self, ct_path, seg_path):\n",
        "        \"\"\"Load and preprocess a single volume pair\"\"\"\n",
        "        # Load volumes\n",
        "        ct_vol = self.load_volume(ct_path)\n",
        "        seg_vol = self.load_volume(seg_path)\n",
        "\n",
        "        # Normalize CT volume\n",
        "        ct_vol = self.normalize_volume(ct_vol)\n",
        "\n",
        "        # Resample to target shape\n",
        "        if ct_vol.shape != self.target_shape:\n",
        "            ct_vol = transform.resize(ct_vol, self.target_shape, mode='constant', anti_aliasing=True)\n",
        "            seg_vol = transform.resize(seg_vol, self.target_shape, mode='constant', order=0, anti_aliasing=False)\n",
        "\n",
        "        # Ensure segmentation values are integers\n",
        "        seg_vol = np.round(seg_vol).astype(np.int64)\n",
        "\n",
        "        return ct_vol, seg_vol\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ct_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ct_path = os.path.join('Data_Subsample/CT', self.ct_files[idx])\n",
        "        seg_path = os.path.join('Data_Subsample/Segmentation', self.seg_files[idx])\n",
        "\n",
        "        # Load and preprocess\n",
        "        ct_vol, seg_vol = self.preprocess_volume(ct_path, seg_path)\n",
        "\n",
        "        # Convert to torch tensors and add channel dimension\n",
        "        ct_vol = torch.FloatTensor(ct_vol).unsqueeze(0)\n",
        "        seg_vol = torch.LongTensor(seg_vol)\n",
        "\n",
        "        # Move to GPU if available\n",
        "        if torch.cuda.is_available():\n",
        "            ct_vol = ct_vol.cuda()\n",
        "            seg_vol = seg_vol.cuda()\n",
        "\n",
        "        return ct_vol, seg_vol\n",
        "\n",
        "# Split data into training and validation sets\n",
        "train_ct, val_ct, train_seg, val_seg = train_test_split(\n",
        "    ct_files, seg_files, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = OvarianCancerDataset(train_ct, train_seg)\n",
        "val_dataset = OvarianCancerDataset(val_ct, val_seg)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, \n",
        "    batch_size=1, \n",
        "    shuffle=True,  # Let PyTorch handle shuffling\n",
        "    num_workers=0,  # Run in main process\n",
        "    pin_memory=True if torch.cuda.is_available() else False\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset, \n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    num_workers=0,  # Run in main process\n",
        "    pin_memory=True if torch.cuda.is_available() else False\n",
        ")\n",
        "\n",
        "print(f'Training samples: {len(train_dataset)}')\n",
        "print(f'Validation samples: {len(val_dataset)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SEBlock(nn.Module):\n",
        "    \"\"\"Squeeze-and-Excitation block for channel attention\"\"\"\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super().__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channels, channels // reduction),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channels // reduction, channels),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1, 1)\n",
        "        return x * y\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"Enhanced double convolution block with SE attention\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.se = SEBlock(out_channels)\n",
        "        self.residual = nn.Sequential(\n",
        "            nn.Conv3d(in_channels, out_channels, kernel_size=1),\n",
        "            nn.BatchNorm3d(out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        main = self.double_conv(x)\n",
        "        main = self.se(main)\n",
        "        residual = self.residual(x)\n",
        "        return F.relu(main + residual)\n",
        "\n",
        "class UNet3D(nn.Module):\n",
        "    \"\"\"3D U-Net with SE attention and residual connections\"\"\"\n",
        "    def __init__(self, in_channels=1, out_channels=3, features=[16, 32, 64, 128]):\n",
        "        super(UNet3D, self).__init__()\n",
        "        self.encoder = nn.ModuleList()\n",
        "        self.decoder = nn.ModuleList()\n",
        "        self.pool = nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Encoder\n",
        "        in_channels_temp = in_channels\n",
        "        for feature in features:\n",
        "            self.encoder.append(DoubleConv(in_channels_temp, feature))\n",
        "            in_channels_temp = feature\n",
        "\n",
        "        # Decoder\n",
        "        for feature in reversed(features[:-1]):\n",
        "            # Upsampling\n",
        "            self.decoder.append(\n",
        "                nn.Sequential(\n",
        "                    nn.ConvTranspose3d(\n",
        "                        features[features.index(feature)+1],\n",
        "                        feature,\n",
        "                        kernel_size=2,\n",
        "                        stride=2\n",
        "                    ),\n",
        "                    nn.BatchNorm3d(feature),\n",
        "                    nn.ReLU(inplace=True)\n",
        "                )\n",
        "            )\n",
        "            # Double conv after concatenation\n",
        "            self.decoder.append(DoubleConv(feature * 2, feature))\n",
        "\n",
        "        self.bottleneck = DoubleConv(features[-2], features[-1])\n",
        "        self.final_conv = nn.Conv3d(features[0], out_channels, kernel_size=1)\n",
        "\n",
        "        # Regularization\n",
        "        self.dropout = nn.Dropout3d(p=0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip_connections = []\n",
        "\n",
        "        # Encoder\n",
        "        for encoder in self.encoder[:-1]:\n",
        "            x = encoder(x)\n",
        "            skip_connections.append(x)\n",
        "            x = self.pool(x)\n",
        "            x = self.dropout(x)\n",
        "\n",
        "        x = self.bottleneck(x)\n",
        "\n",
        "        # Decoder\n",
        "        skip_connections = skip_connections[::-1]\n",
        "        for idx in range(0, len(self.decoder), 2):\n",
        "            x = self.decoder[idx](x)\n",
        "            skip = skip_connections[idx//2]\n",
        "\n",
        "            # Handle different sizes\n",
        "            if x.shape != skip.shape:\n",
        "                x = F.interpolate(x, size=skip.shape[2:])\n",
        "\n",
        "            concat_skip = torch.cat((skip, x), dim=1)\n",
        "            x = self.decoder[idx+1](concat_skip)\n",
        "            x = self.dropout(x)\n",
        "\n",
        "        return self.final_conv(x)\n",
        "\n",
        "# Initialize model and move to GPU if available\n",
        "model = UNet3D(in_channels=1, out_channels=3)\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "print(f\"Model architecture:\\n{model}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 5Ô∏è‚É£ Training and Evaluation\n",
        "\n",
        "## üèÉ‚Äç‚ôÇÔ∏è Training Process\n",
        "Our training pipeline includes:\n",
        "- Batch-wise training with GPU acceleration\n",
        "- Learning rate scheduling with ReduceLROnPlateau\n",
        "- Early stopping to prevent overfitting\n",
        "- Model checkpointing to save best weights\n",
        "- Memory optimization with periodic cache clearing\n",
        "\n",
        "## üìà Evaluation Metrics\n",
        "We'll monitor:\n",
        "- Dice coefficient per class\n",
        "- Overall segmentation accuracy\n",
        "- Class-wise precision and recall\n",
        "- Training and validation loss curves\n",
        "\n",
        "## üîç Visualization\n",
        "During and after training, we'll visualize:\n",
        "- Sample predictions on validation data\n",
        "- Training progress and learning curves\n",
        "- Segmentation overlays on CT slices\n",
        "\n",
        "Let's implement the training loop and evaluation functions:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_epoch(model, loader, optimizer, criterion):\n",
        "    \"\"\"Train the model for one epoch\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    num_batches = len(loader)\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(loader):\n",
        "        # Move data to GPU if available\n",
        "        if torch.cuda.is_available():\n",
        "            data = data.cuda()\n",
        "            target = target.cuda()\n",
        "\n",
        "        # Clear gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update metrics\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Print progress and clear cache\n",
        "        if batch_idx % 5 == 0:\n",
        "            print(f'Batch {batch_idx}/{num_batches}, Loss: {loss.item():.4f}')\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()  # Clear GPU cache periodically\n",
        "\n",
        "    return total_loss / num_batches\n",
        "\n",
        "def validate(model, loader, criterion):\n",
        "    \"\"\"Validate the model\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    num_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in loader:\n",
        "            # Move data to GPU if available\n",
        "            if torch.cuda.is_available():\n",
        "                data = data.cuda()\n",
        "                target = target.cuda()\n",
        "            \n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "    return total_loss / num_batches\n",
        "\n",
        "def predict_volume(model, ct_volume):\n",
        "    \"\"\"Generate predictions for a single volume\"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        if torch.cuda.is_available():\n",
        "            ct_volume = ct_volume.cuda()\n",
        "        pred = model(ct_volume.unsqueeze(0))\n",
        "        pred = F.softmax(pred, dim=1)\n",
        "        pred = torch.argmax(pred, dim=1)\n",
        "    return pred[0].cpu().numpy()\n",
        "\n",
        "# Training setup\n",
        "criterion = CombinedLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.01)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', factor=0.1, patience=2, verbose=True\n",
        ")\n",
        "\n",
        "# Training loop\n",
        "n_epochs = 30\n",
        "best_val_loss = float('inf')\n",
        "patience = 5\n",
        "patience_counter = 0\n",
        "\n",
        "print(\"Starting training...\")\n",
        "for epoch in range(n_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{n_epochs}\")\n",
        "    \n",
        "    # Training phase\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
        "    print(f\"Training Loss: {train_loss:.4f}\")\n",
        "    \n",
        "    # Validation phase\n",
        "    val_loss = validate(model, val_loader, criterion)\n",
        "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
        "    \n",
        "    # Learning rate scheduling\n",
        "    scheduler.step(val_loss)\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    print(f\"Current learning rate: {current_lr:.2e}\")\n",
        "    \n",
        "    # Model checkpointing\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "        patience_counter = 0\n",
        "        print(\"Saved new best model!\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "    \n",
        "    # Early stopping\n",
        "    if patience_counter >= patience:\n",
        "        print(f\"\\nEarly stopping triggered after {epoch+1} epochs\")\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 6Ô∏è‚É£ Discussion and Future Work\n",
        "\n",
        "## üîç Technical Analysis\n",
        "Consider and discuss the following aspects of your implementation:\n",
        "\n",
        "### Data Challenges\n",
        "- What difficulties did you encounter with the medical imaging data?\n",
        "- How effective was your preprocessing pipeline?\n",
        "- What additional data augmentation techniques could be beneficial?\n",
        "\n",
        "### Model Performance\n",
        "- How well did the model segment different tissue types?\n",
        "- What were the main sources of errors?\n",
        "- How could the architecture be improved?\n",
        "\n",
        "## üè• Clinical Impact\n",
        "Reflect on the clinical applications:\n",
        "\n",
        "### Current Capabilities\n",
        "- How reliable is the model for clinical use?\n",
        "- What are the limitations of the current implementation?\n",
        "- How does it compare to human expert performance?\n",
        "\n",
        "### Future Improvements\n",
        "- What additional validation would be needed for clinical deployment?\n",
        "- How could the model be integrated into clinical workflows?\n",
        "- What safety measures should be implemented?\n",
        "\n",
        "## üöÄ Next Steps\n",
        "Consider these potential improvements:\n",
        "\n",
        "### Technical Enhancements\n",
        "- Implement additional data augmentation techniques\n",
        "- Experiment with different model architectures\n",
        "- Add uncertainty quantification\n",
        "- Optimize for inference speed\n",
        "\n",
        "### Clinical Integration\n",
        "- Develop a user-friendly interface\n",
        "- Add reporting and visualization tools\n",
        "- Implement quality assurance measures\n",
        "- Design clinical validation studies\n",
        "\n",
        "Write your answers and reflections below:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1Jz7yec3bzO"
      },
      "source": [
        "# 9. Discussion Questions\n",
        "\n",
        "Please answer the following questions based on your implementation and results:\n",
        "\n",
        "1. **Data Analysis**\n",
        "   - What challenges did you encounter with the medical imaging data?\n",
        "   - How did you handle class imbalance?\n",
        "\n",
        "2. **Model Performance**\n",
        "   - How well did the model perform on different classes?\n",
        "   - What were the main sources of error?\n",
        "\n",
        "3. **Clinical Relevance**\n",
        "   - How might this model be useful in a clinical setting?\n",
        "   - What additional validation would be needed?\n",
        "\n",
        "4. **Improvements**\n",
        "   - What modifications could improve the model's performance?\n",
        "   - How could the preprocessing pipeline be enhanced?\n",
        "\n",
        "Write your answers below:\n",
        "\n",
        "1. Data Analysis:\n",
        "   > Your answer here\n",
        "\n",
        "2. Model Performance:\n",
        "   > Your answer here\n",
        "\n",
        "3. Clinical Relevance:\n",
        "   > Your answer here\n",
        "\n",
        "4. Improvements:\n",
        "   > Your answer here\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
