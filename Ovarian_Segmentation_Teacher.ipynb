{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Ovarian Cancer Segmentation Lab\n",
    "\n",
    "This lab focuses on medical image segmentation for ovarian cancer detection using CT scans. You will work with volumetric medical data (NIfTI format) to build and train a U-Net model for segmenting different types of cancer tissues.\n",
    "\n",
    "## Task Overview\n",
    "You will segment CT volumes into three classes:\n",
    "- Class 0: Background\n",
    "- Class 1: Primary ovarian cancer\n",
    "- Class 2: Metastasis\n",
    "\n",
    "## ðŸŽ¯ Learning Objectives\n",
    "- Work with medical imaging data in NIfTI format\n",
    "- Implement a 3D U-Net architecture\n",
    "- Train a segmentation model\n",
    "- Evaluate medical imaging results\n",
    "\n",
    "Let's begin! ðŸš€\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install numpy --quiet\n",
    "!pip install scipy --quiet\n",
    "!pip install scikit-learn --quiet\n",
    "!pip install scikit-image nibabel gdown torch torchvision --quiet\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "from skimage import transform\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set up GPU if available\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"WARNING: CUDA is not available. Please make sure to enable GPU in Runtime > Change runtime type\")\n",
    "    print(\"Current device: CPU\")\n",
    "else:\n",
    "    # Set default tensor type to CUDA\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"Using device: {device}\")\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Available memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Functions\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-5):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        \n",
    "    def forward(self, predictions, targets):\n",
    "        # predictions shape: (batch_size, n_classes, d1, d2, d3)\n",
    "        # targets shape: (batch_size, d1, d2, d3)\n",
    "        \n",
    "        # Convert predictions to probabilities\n",
    "        predictions = F.softmax(predictions, dim=1)\n",
    "        \n",
    "        # One-hot encode targets\n",
    "        n_classes = predictions.shape[1]\n",
    "        one_hot_targets = F.one_hot(targets, n_classes).permute(0, 4, 1, 2, 3).float()\n",
    "        \n",
    "        # Calculate Dice score for each class\n",
    "        numerator = 2 * (predictions * one_hot_targets).sum(dim=(2, 3, 4))\n",
    "        denominator = predictions.sum(dim=(2, 3, 4)) + one_hot_targets.sum(dim=(2, 3, 4))\n",
    "        dice_scores = (numerator + self.smooth) / (denominator + self.smooth)\n",
    "        \n",
    "        # Average over classes and batch\n",
    "        return 1 - dice_scores.mean()\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-5, ce_weight=0.5):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        self.ce_weight = ce_weight\n",
    "        self.dice_loss = DiceLoss(smooth=smooth)\n",
    "        \n",
    "    def forward(self, predictions, targets):\n",
    "        # Calculate class weights based on inverse frequency\n",
    "        n_classes = predictions.shape[1]\n",
    "        class_counts = torch.bincount(targets.flatten(), minlength=n_classes).float()\n",
    "        total_pixels = class_counts.sum()\n",
    "        class_weights = total_pixels / (class_counts * n_classes + self.smooth)\n",
    "        class_weights = class_weights.to(predictions.device)\n",
    "        \n",
    "        # Dice Loss\n",
    "        dice_loss = self.dice_loss(predictions, targets)\n",
    "        \n",
    "        # Weighted Cross Entropy Loss\n",
    "        ce_loss = F.cross_entropy(predictions, targets, weight=class_weights)\n",
    "        \n",
    "        # Combine losses\n",
    "        return dice_loss + self.ce_weight * ce_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract dataset\n",
    "file_id = '1Wo4h6ZVIFygVvqd68ApwWIdPQk3l7gkO'\n",
    "output = 'Data_Subsample.zip'\n",
    "\n",
    "if not os.path.exists('Data_Subsample.zip'):\n",
    "    import subprocess\n",
    "    subprocess.run(['gdown', '--id', file_id, '-O', output])\n",
    "\n",
    "# Extract data if not already extracted\n",
    "if not os.path.exists('Data_Subsample'):\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(output, 'r') as zip_ref:\n",
    "        zip_ref.extractall('.')\n",
    "\n",
    "# List available files\n",
    "ct_files = sorted([f for f in os.listdir('Data_Subsample/CT') if f.endswith('.nii.gz')])\n",
    "seg_files = sorted([f for f in os.listdir('Data_Subsample/Segmentation') if f.endswith('.nii.gz')])\n",
    "\n",
    "print(f'Number of CT volumes: {len(ct_files)}')\n",
    "print(f'Number of segmentation masks: {len(seg_files)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 1. Environment Setup\n",
    "\n",
    "First, let's install the required packages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Functions\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-5):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        \n",
    "    def forward(self, predictions, targets):\n",
    "        # predictions shape: (batch_size, n_classes, d1, d2, d3)\n",
    "        # targets shape: (batch_size, d1, d2, d3)\n",
    "        \n",
    "        # Convert predictions to probabilities\n",
    "        predictions = F.softmax(predictions, dim=1)\n",
    "        \n",
    "        # One-hot encode targets\n",
    "        n_classes = predictions.shape[1]\n",
    "        one_hot_targets = F.one_hot(targets, n_classes).permute(0, 4, 1, 2, 3).float()\n",
    "        \n",
    "        # Calculate Dice score for each class\n",
    "        numerator = 2 * (predictions * one_hot_targets).sum(dim=(2, 3, 4))\n",
    "        denominator = predictions.sum(dim=(2, 3, 4)) + one_hot_targets.sum(dim=(2, 3, 4))\n",
    "        dice_scores = (numerator + self.smooth) / (denominator + self.smooth)\n",
    "        \n",
    "        # Average over classes and batch\n",
    "        return 1 - dice_scores.mean()\n",
    "\n",
    "# Combined loss for handling class imbalance\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-5, ce_weight=0.5):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        self.ce_weight = ce_weight\n",
    "        self.dice_loss = DiceLoss(smooth=smooth)\n",
    "        \n",
    "    def forward(self, predictions, targets):\n",
    "        # Calculate class weights based on inverse frequency\n",
    "        n_classes = predictions.shape[1]\n",
    "        class_counts = torch.bincount(targets.flatten(), minlength=n_classes).float()\n",
    "        total_pixels = class_counts.sum()\n",
    "        class_weights = total_pixels / (class_counts * n_classes + self.smooth)\n",
    "        class_weights = class_weights.to(predictions.device)\n",
    "        \n",
    "        # Dice Loss\n",
    "        dice_loss = self.dice_loss(predictions, targets)\n",
    "        \n",
    "        # Weighted Cross Entropy Loss\n",
    "        ce_loss = F.cross_entropy(predictions, targets, weight=class_weights)\n",
    "        \n",
    "        # Combine losses\n",
    "        return dice_loss + self.ce_weight * ce_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages with specific versions known to work together\n",
    "!pip install numpy --quiet\n",
    "!pip install scipy --quiet\n",
    "!pip install scikit-learn --quiet\n",
    "!pip install scikit-image nibabel gdown torch torchvision --quiet\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "from skimage import transform\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Force CUDA device if available\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"WARNING: CUDA is not available. Please make sure to enable GPU in Runtime > Change runtime type\")\n",
    "    print(\"Current device: CPU\")\n",
    "else:\n",
    "    # Set default tensor type to CUDA\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"Using device: {device}\")\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Available memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "# Print versions for debugging\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "try:\n",
    "    import sklearn\n",
    "    print(f\"scikit-learn version: {sklearn.__version__}\")\n",
    "except:\n",
    "    print(\"scikit-learn import failed\")\n",
    "\n",
    "# Combined loss for handling class imbalance\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-5, ce_weight=0.5):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        self.ce_weight = ce_weight\n",
    "        \n",
    "    def forward(self, predictions, targets):\n",
    "        # predictions shape: (batch_size, n_classes, d1, d2, d3)\n",
    "        # targets shape: (batch_size, d1, d2, d3)\n",
    "        \n",
    "        # Calculate class weights based on inverse frequency\n",
    "        n_classes = predictions.shape[1]\n",
    "        class_counts = torch.bincount(targets.flatten(), minlength=n_classes).float()\n",
    "        total_pixels = class_counts.sum()\n",
    "        class_weights = total_pixels / (class_counts * n_classes + self.smooth)\n",
    "        class_weights = class_weights.to(predictions.device)\n",
    "        \n",
    "        # Dice Loss\n",
    "        predictions_softmax = F.softmax(predictions, dim=1)\n",
    "        one_hot_targets = F.one_hot(targets, n_classes).permute(0, 4, 1, 2, 3).float()\n",
    "        \n",
    "        # Weighted Dice for each class\n",
    "        numerator = 2 * (predictions_softmax * one_hot_targets).sum(dim=(2, 3, 4))\n",
    "        denominator = predictions_softmax.sum(dim=(2, 3, 4)) + one_hot_targets.sum(dim=(2, 3, 4))\n",
    "        dice_per_class = (numerator + self.smooth) / (denominator + self.smooth)\n",
    "        weighted_dice = (dice_per_class * class_weights).mean()\n",
    "        dice_loss = 1 - weighted_dice\n",
    "        \n",
    "        # Weighted Cross Entropy Loss\n",
    "        ce_loss = F.cross_entropy(predictions, targets, weight=class_weights)\n",
    "        \n",
    "        # Combine losses\n",
    "        return dice_loss + self.ce_weight * ce_loss\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Download and Extraction\n",
    "\n",
    "Download and extract the dataset containing CT volumes and segmentation masks:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data if not already present\n",
    "file_id = '1Wo4h6ZVIFygVvqd68ApwWIdPQk3l7gkO'\n",
    "output = 'Data_Subsample.zip'\n",
    "\n",
    "if not os.path.exists('Data_Subsample.zip'):\n",
    "    !gdown --id $file_id -O $output\n",
    "\n",
    "# Extract data if not already extracted\n",
    "if not os.path.exists('Data_Subsample'):\n",
    "    !unzip -o Data_Subsample.zip\n",
    "\n",
    "# List available files\n",
    "ct_files = sorted([f for f in os.listdir('Data_Subsample/CT') if f.endswith('.nii.gz')])\n",
    "seg_files = sorted([f for f in os.listdir('Data_Subsample/Segmentation') if f.endswith('.nii.gz')])\n",
    "\n",
    "print(f'Number of CT volumes: {len(ct_files)}')\n",
    "print(f'Number of segmentation masks: {len(seg_files)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Let's explore the data structure and visualize some examples.\n",
    "\n",
    "### Questions to consider:\n",
    "1. What are the typical dimensions of the CT volumes?\n",
    "2. How are the classes distributed in the segmentation masks?\n",
    "3. What preprocessing steps might be necessary?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class definition\n",
    "class OvarianCancerDataset(Dataset):\n",
    "    def __init__(self, ct_files, seg_files, target_shape=(64, 64, 64)):\n",
    "        self.ct_files = ct_files\n",
    "        self.seg_files = seg_files\n",
    "        self.target_shape = target_shape\n",
    "        \n",
    "    def normalize_volume(self, volume):\n",
    "        \"\"\"Normalize volume to [0,1] range\"\"\"\n",
    "        min_val = np.min(volume)\n",
    "        max_val = np.max(volume)\n",
    "        if max_val - min_val == 0:\n",
    "            return volume\n",
    "        return (volume - min_val) / (max_val - min_val)\n",
    "    \n",
    "    def load_volume(self, file_path):\n",
    "        \"\"\"Load a NIfTI volume and return its data\"\"\"\n",
    "        return nib.load(file_path).get_fdata()\n",
    "    \n",
    "    def preprocess_volume(self, ct_path, seg_path):\n",
    "        \"\"\"Load and preprocess a single volume pair\"\"\"\n",
    "        # Load volumes\n",
    "        ct_vol = self.load_volume(ct_path)\n",
    "        seg_vol = self.load_volume(seg_path)\n",
    "        \n",
    "        # Normalize CT volume\n",
    "        ct_vol = self.normalize_volume(ct_vol)\n",
    "        \n",
    "        # Resample to target shape\n",
    "        if ct_vol.shape != self.target_shape:\n",
    "            ct_vol = transform.resize(ct_vol, self.target_shape, mode='constant', anti_aliasing=True)\n",
    "            seg_vol = transform.resize(seg_vol, self.target_shape, mode='constant', order=0, anti_aliasing=False)\n",
    "        \n",
    "        # Ensure segmentation values are integers\n",
    "        seg_vol = np.round(seg_vol).astype(np.int64)\n",
    "        \n",
    "        return ct_vol, seg_vol\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ct_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        ct_path = os.path.join('Data_Subsample/CT', self.ct_files[idx])\n",
    "        seg_path = os.path.join('Data_Subsample/Segmentation', self.seg_files[idx])\n",
    "        \n",
    "        # Load and preprocess\n",
    "        ct_vol, seg_vol = self.preprocess_volume(ct_path, seg_path)\n",
    "        \n",
    "        # Convert to torch tensors and add channel dimension\n",
    "        ct_vol = torch.FloatTensor(ct_vol).unsqueeze(0)\n",
    "        seg_vol = torch.LongTensor(seg_vol)\n",
    "        \n",
    "        # Move to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            ct_vol = ct_vol.cuda()\n",
    "            seg_vol = seg_vol.cuda()\n",
    "            \n",
    "        return ct_vol, seg_vol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization functions\n",
    "def plot_slices(ct_volume, seg_mask=None, slice_nums=None, cmap='gray'):\n",
    "    \"\"\"Plot multiple slices from a volume with optional segmentation overlay\"\"\"\n",
    "    if slice_nums is None:\n",
    "        slice_nums = [ct_volume.shape[2]//2]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(slice_nums), figsize=(15, 5))\n",
    "    if len(slice_nums) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for ax, slice_num in zip(axes, slice_nums):\n",
    "        ax.imshow(ct_volume[:,:,slice_num], cmap=cmap)\n",
    "        if seg_mask is not None:\n",
    "            # Create a masked array for the segmentation\n",
    "            mask_slice = seg_mask[:,:,slice_num]\n",
    "            ax.imshow(mask_slice, alpha=0.3, cmap='jet')\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'Slice {slice_num}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create dataset instance for visualization\n",
    "dataset = OvarianCancerDataset([ct_files[0]], [seg_files[0]])\n",
    "\n",
    "# Get preprocessed data\n",
    "ct_path = os.path.join('Data_Subsample/CT', ct_files[0])\n",
    "seg_path = os.path.join('Data_Subsample/Segmentation', seg_files[0])\n",
    "ct_processed, seg_processed = dataset.preprocess_volume(ct_path, seg_path)\n",
    "\n",
    "print('Processed shapes:', ct_processed.shape, seg_processed.shape)\n",
    "print('Value ranges - CT:', ct_processed.min(), ct_processed.max(),\n",
    "      '\\nSegmentation:', seg_processed.min(), seg_processed.max())\n",
    "\n",
    "# Visualize middle slice\n",
    "mid_slice = ct_processed.shape[2] // 2\n",
    "plot_slices(ct_processed, seg_processed, [mid_slice])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_volume(file_path):\n",
    "    \"\"\"Load a NIfTI volume and return its data\"\"\"\n",
    "    return nib.load(file_path).get_fdata()\n",
    "\n",
    "def plot_slices(ct_volume, seg_mask=None, slice_nums=None, cmap='gray'):\n",
    "    \"\"\"Plot multiple slices from a volume with optional segmentation overlay\"\"\"\n",
    "    if slice_nums is None:\n",
    "        slice_nums = [ct_volume.shape[2]//2]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(slice_nums), figsize=(15, 5))\n",
    "    if len(slice_nums) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for ax, slice_num in zip(axes, slice_nums):\n",
    "        ax.imshow(ct_volume[:,:,slice_num], cmap=cmap)\n",
    "        if seg_mask is not None:\n",
    "            # Create a masked array for the segmentation\n",
    "            mask_slice = seg_mask[:,:,slice_num]\n",
    "            ax.imshow(mask_slice, alpha=0.3, cmap='jet')\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'Slice {slice_num}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Load and examine first volume\n",
    "ct_path = os.path.join('Data_Subsample/CT', ct_files[0])\n",
    "seg_path = os.path.join('Data_Subsample/Segmentation', seg_files[0])\n",
    "\n",
    "ct_vol = load_volume(ct_path)\n",
    "seg_vol = load_volume(seg_path)\n",
    "\n",
    "print('CT volume shape:', ct_vol.shape)\n",
    "print('Segmentation mask shape:', seg_vol.shape)\n",
    "print('\\nUnique classes in segmentation:', np.unique(seg_vol))\n",
    "\n",
    "# Plot middle slices\n",
    "middle_slice = ct_vol.shape[2]//2\n",
    "plot_slices(ct_vol, seg_vol, [middle_slice-20, middle_slice, middle_slice+20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Preprocessing\n",
    "\n",
    "We'll implement several preprocessing steps:\n",
    "1. Intensity normalization\n",
    "2. Resampling to a common size\n",
    "3. Data augmentation\n",
    "\n",
    "### Questions to consider:\n",
    "1. Why is normalization important for medical images?\n",
    "2. What are appropriate augmentation techniques for 3D medical data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary dataset instance for preprocessing\n",
    "temp_dataset = OvarianCancerDataset([ct_files[0]], [seg_files[0]])\n",
    "ct_processed, seg_processed = temp_dataset.preprocess_volume(\n",
    "    os.path.join('Data_Subsample/CT', ct_files[0]),\n",
    "    os.path.join('Data_Subsample/Segmentation', seg_files[0])\n",
    ")\n",
    "\n",
    "print('Processed shapes:', ct_processed.shape, seg_processed.shape)\n",
    "print('Value ranges - CT:', ct_processed.min(), ct_processed.max(),\n",
    "      '\\nSegmentation:', seg_processed.min(), seg_processed.max())\n",
    "\n",
    "# Visualize processed data - using middle slice (31 for 64x64x64 volume)\n",
    "mid_slice = ct_processed.shape[2] // 2  # This will be 31 for a 64x64x64 volume\n",
    "plot_slices(ct_processed, seg_processed, [mid_slice])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and Model Setup\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class OvarianCancerDataset(Dataset):\n",
    "    def __init__(self, ct_files, seg_files, target_shape=(64, 64, 64)):\n",
    "        self.ct_files = ct_files\n",
    "        self.seg_files = seg_files\n",
    "        self.target_shape = target_shape\n",
    "        \n",
    "    def normalize_volume(self, volume):\n",
    "        \"\"\"Normalize volume to [0,1] range\"\"\"\n",
    "        min_val = np.min(volume)\n",
    "        max_val = np.max(volume)\n",
    "        if max_val - min_val == 0:\n",
    "            return volume\n",
    "        return (volume - min_val) / (max_val - min_val)\n",
    "    \n",
    "    def load_volume(self, file_path):\n",
    "        \"\"\"Load a NIfTI volume and return its data\"\"\"\n",
    "        return nib.load(file_path).get_fdata()\n",
    "    \n",
    "    def preprocess_volume(self, ct_path, seg_path):\n",
    "        \"\"\"Load and preprocess a single volume pair\"\"\"\n",
    "        # Load volumes\n",
    "        ct_vol = self.load_volume(ct_path)\n",
    "        seg_vol = self.load_volume(seg_path)\n",
    "        \n",
    "        # Normalize CT volume\n",
    "        ct_vol = self.normalize_volume(ct_vol)\n",
    "        \n",
    "        # Resample to target shape\n",
    "        if ct_vol.shape != self.target_shape:\n",
    "            ct_vol = transform.resize(ct_vol, self.target_shape, mode='constant', anti_aliasing=True)\n",
    "            seg_vol = transform.resize(seg_vol, self.target_shape, mode='constant', order=0, anti_aliasing=False)\n",
    "        \n",
    "        # Ensure segmentation values are integers\n",
    "        seg_vol = np.round(seg_vol).astype(np.int64)\n",
    "        \n",
    "        return ct_vol, seg_vol\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ct_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        ct_path = os.path.join('Data_Subsample/CT', self.ct_files[idx])\n",
    "        seg_path = os.path.join('Data_Subsample/Segmentation', self.seg_files[idx])\n",
    "        \n",
    "        # Load and preprocess\n",
    "        ct_vol, seg_vol = self.preprocess_volume(ct_path, seg_path)\n",
    "        \n",
    "        # Convert to torch tensors and add channel dimension\n",
    "        ct_vol = torch.FloatTensor(ct_vol).unsqueeze(0)\n",
    "        seg_vol = torch.LongTensor(seg_vol)\n",
    "        \n",
    "        # Move to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            ct_vol = ct_vol.cuda()\n",
    "            seg_vol = seg_vol.cuda()\n",
    "            \n",
    "        return ct_vol, seg_vol\n",
    "\n",
    "# Split data\n",
    "train_ct, val_ct, train_seg, val_seg = train_test_split(\n",
    "    ct_files, seg_files, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create datasets with target shape\n",
    "target_shape = (64, 64, 64)  # You can adjust this if needed\n",
    "train_dataset = OvarianCancerDataset(train_ct, train_seg, target_shape=target_shape)\n",
    "val_dataset = OvarianCancerDataset(val_ct, val_seg, target_shape=target_shape)\n",
    "\n",
    "# Create dataloaders with smaller batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1)\n",
    "\n",
    "print(f'Training samples: {len(train_dataset)}')\n",
    "print(f'Validation samples: {len(val_dataset)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet3D(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=3, features=[16, 32, 64, 128]):\n",
    "        super(UNet3D, self).__init__()\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.decoder = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Encoder\n",
    "        in_channels_temp = in_channels\n",
    "        for feature in features:\n",
    "            self.encoder.append(DoubleConv(in_channels_temp, feature))\n",
    "            in_channels_temp = feature\n",
    "\n",
    "        # Decoder\n",
    "        for feature in reversed(features[:-1]):\n",
    "            # Upsampling\n",
    "            self.decoder.append(\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose3d(\n",
    "                        features[features.index(feature)+1],\n",
    "                        feature,\n",
    "                        kernel_size=2,\n",
    "                        stride=2\n",
    "                    ),\n",
    "                    nn.BatchNorm3d(feature),\n",
    "                    nn.ReLU(inplace=True)\n",
    "                )\n",
    "            )\n",
    "            # Double conv after concatenation\n",
    "            self.decoder.append(DoubleConv(feature * 2, feature))\n",
    "\n",
    "        self.bottleneck = DoubleConv(features[-2], features[-1])\n",
    "        self.final_conv = nn.Conv3d(features[0], out_channels, kernel_size=1)\n",
    "        \n",
    "        # Regularization\n",
    "        self.dropout = nn.Dropout3d(p=0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "\n",
    "        # Encoder\n",
    "        for encoder in self.encoder[:-1]:\n",
    "            x = encoder(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        # Decoder\n",
    "        skip_connections = skip_connections[::-1]\n",
    "        for idx in range(0, len(self.decoder), 2):\n",
    "            x = self.decoder[idx](x)\n",
    "            skip = skip_connections[idx//2]\n",
    "            \n",
    "            # Handle different sizes\n",
    "            if x.shape != skip.shape:\n",
    "                x = F.interpolate(x, size=skip.shape[2:])\n",
    "                \n",
    "            concat_skip = torch.cat((skip, x), dim=1)\n",
    "            x = self.decoder[idx+1](concat_skip)\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        return self.final_conv(x)\n",
    "\n",
    "# Initialize model and move to GPU if available\n",
    "model = UNet3D(in_channels=1, out_channels=3)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "# Initialize loss function and optimizer\n",
    "criterion = CombinedLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Model architecture:\\n{model}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Validation Functions\n",
    "def train_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        # Move to GPU and clear gradients\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update metrics\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Print progress and clear cache\n",
    "        if batch_idx % 5 == 0:\n",
    "            print(f'Batch {batch_idx}/{len(loader)}, Loss: {loss.item():.4f}')\n",
    "            torch.cuda.empty_cache()  # Clear GPU cache periodically\n",
    "    \n",
    "    return total_loss / num_batches\n",
    "\n",
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "    return total_loss / num_batches\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 100\n",
    "best_val_loss = float('inf')\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{n_epochs}\")\n",
    "    \n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
    "    val_loss = validate(model, val_loader, criterion)\n",
    "    \n",
    "    print(f\"Training Loss: {train_loss:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        # Save best model\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping triggered after {epoch+1} epochs\")\n",
    "            break\n",
    "            \n",
    "    # Clear GPU cache after each epoch\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import preprocessing function from previous cell\n",
    "from __main__ import preprocess_volume\n",
    "\n",
    "class OvarianCancerDataset(Dataset):\n",
    "    def __init__(self, ct_files, seg_files, target_shape=(64, 64, 64)):\n",
    "        self.ct_files = ct_files\n",
    "        self.seg_files = seg_files\n",
    "        self.target_shape = target_shape\n",
    "        \n",
    "    def normalize_volume(self, volume):\n",
    "        \"\"\"Normalize volume to [0,1] range\"\"\"\n",
    "        min_val = np.min(volume)\n",
    "        max_val = np.max(volume)\n",
    "        if max_val - min_val == 0:\n",
    "            return volume\n",
    "        return (volume - min_val) / (max_val - min_val)\n",
    "    \n",
    "    def load_volume(self, file_path):\n",
    "        \"\"\"Load a NIfTI volume and return its data\"\"\"\n",
    "        return nib.load(file_path).get_fdata()\n",
    "    \n",
    "    def preprocess_volume(self, ct_path, seg_path):\n",
    "        \"\"\"Load and preprocess a single volume pair\"\"\"\n",
    "        # Load volumes\n",
    "        ct_vol = self.load_volume(ct_path)\n",
    "        seg_vol = self.load_volume(seg_path)\n",
    "        \n",
    "        # Normalize CT volume\n",
    "        ct_vol = self.normalize_volume(ct_vol)\n",
    "        \n",
    "        # Resample to target shape\n",
    "        if ct_vol.shape != self.target_shape:\n",
    "            ct_vol = transform.resize(ct_vol, self.target_shape, mode='constant', anti_aliasing=True)\n",
    "            seg_vol = transform.resize(seg_vol, self.target_shape, mode='constant', order=0, anti_aliasing=False)\n",
    "        \n",
    "        # Ensure segmentation values are integers\n",
    "        seg_vol = np.round(seg_vol).astype(np.int64)\n",
    "        \n",
    "        return ct_vol, seg_vol\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ct_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        ct_path = os.path.join('Data_Subsample/CT', self.ct_files[idx])\n",
    "        seg_path = os.path.join('Data_Subsample/Segmentation', self.seg_files[idx])\n",
    "        \n",
    "        # Load and preprocess\n",
    "        ct_vol, seg_vol = self.preprocess_volume(ct_path, seg_path)\n",
    "        \n",
    "        # Convert to torch tensors and add channel dimension\n",
    "        ct_vol = torch.FloatTensor(ct_vol).unsqueeze(0)\n",
    "        seg_vol = torch.LongTensor(seg_vol)\n",
    "        \n",
    "        # Move to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            ct_vol = ct_vol.cuda()\n",
    "            seg_vol = seg_vol.cuda()\n",
    "            \n",
    "        return ct_vol, seg_vol\n",
    "\n",
    "# Split data\n",
    "train_ct, val_ct, train_seg, val_seg = train_test_split(\n",
    "    ct_files, seg_files, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = OvarianCancerDataset(train_ct, train_seg)\n",
    "val_dataset = OvarianCancerDataset(val_ct, val_seg)\n",
    "\n",
    "# Create dataloaders with smaller batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1)\n",
    "\n",
    "print(f'Training samples: {len(train_dataset)}')\n",
    "print(f'Validation samples: {len(val_dataset)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_volume(volume):\n",
    "    \"\"\"Normalize volume to [0,1] range\"\"\"\n",
    "    min_val = np.min(volume)\n",
    "    max_val = np.max(volume)\n",
    "    if max_val - min_val == 0:\n",
    "        return volume\n",
    "    return (volume - min_val) / (max_val - min_val)\n",
    "\n",
    "def preprocess_volume(ct_path, seg_path, target_shape=(64, 64, 64)):\n",
    "    \"\"\"Load and preprocess a single volume pair\"\"\"\n",
    "    # Load volumes\n",
    "    ct_vol = load_volume(ct_path)\n",
    "    seg_vol = load_volume(seg_path)\n",
    "    \n",
    "    # Normalize CT volume\n",
    "    ct_vol = normalize_volume(ct_vol)\n",
    "    \n",
    "    # Resample to target shape\n",
    "    if ct_vol.shape != target_shape:\n",
    "        ct_vol = transform.resize(ct_vol, target_shape, mode='constant', anti_aliasing=True)\n",
    "        seg_vol = transform.resize(seg_vol, target_shape, mode='constant', order=0, anti_aliasing=False)\n",
    "    \n",
    "    # Ensure segmentation values are integers\n",
    "    seg_vol = np.round(seg_vol).astype(np.int64)\n",
    "    \n",
    "    return ct_vol, seg_vol\n",
    "\n",
    "# Example preprocessing\n",
    "ct_processed, seg_processed = preprocess_volume(ct_path, seg_path)\n",
    "print('Processed shapes:', ct_processed.shape, seg_processed.shape)\n",
    "print('Value ranges - CT:', ct_processed.min(), ct_processed.max(),\n",
    "      '\\nSegmentation:', seg_processed.min(), seg_processed.max())\n",
    "\n",
    "# Visualize processed data\n",
    "plot_slices(ct_processed, seg_processed, [64])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Dataset and DataLoader\n",
    "\n",
    "Create a PyTorch dataset for efficient data handling:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OvarianCancerDataset(Dataset):\n",
    "    def __init__(self, ct_files, seg_files, transform=None):\n",
    "        self.ct_files = ct_files\n",
    "        self.seg_files = seg_files\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ct_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        ct_path = os.path.join('Data_Subsample/CT', self.ct_files[idx])\n",
    "        seg_path = os.path.join('Data_Subsample/Segmentation', self.seg_files[idx])\n",
    "        \n",
    "        # Load and preprocess\n",
    "        ct_vol, seg_vol = preprocess_volume(ct_path, seg_path)\n",
    "        \n",
    "        # Convert to torch tensors\n",
    "        ct_vol = torch.FloatTensor(ct_vol).unsqueeze(0)  # Add channel dimension\n",
    "        seg_vol = torch.LongTensor(seg_vol)\n",
    "        \n",
    "        if self.transform:\n",
    "            ct_vol = self.transform(ct_vol)\n",
    "        \n",
    "        return ct_vol, seg_vol\n",
    "\n",
    "# Split data\n",
    "train_ct, val_ct, train_seg, val_seg = train_test_split(\n",
    "    ct_files, seg_files, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = OvarianCancerDataset(train_ct, train_seg)\n",
    "val_dataset = OvarianCancerDataset(val_ct, val_seg)\n",
    "\n",
    "# Create dataloaders with smaller batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1)\n",
    "\n",
    "print(f'Training samples: {len(train_dataset)}')\n",
    "print(f'Validation samples: {len(val_dataset)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Model Architecture\n",
    "\n",
    "Implement a simplified 3D U-Net for segmentation:\n",
    "\n",
    "### Questions to consider:\n",
    "1. Why is U-Net particularly suitable for medical image segmentation?\n",
    "2. What modifications might improve performance?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Model Architecture and Training\n",
    "\n",
    "print(\"Building and training 3D U-Net for medical image segmentation...\")\n",
    "\n",
    "# Questions to consider:\n",
    "# 1. Why is U-Net particularly suitable for medical image segmentation?\n",
    "# 2. What modifications might improve performance?\n",
    "# 3. How does the training process affect segmentation quality?\n",
    "\n",
    "# Define model components\n",
    "class SEBlock(nn.Module):\n",
    "    \"\"\"Squeeze-and-Excitation block for channel attention\"\"\"\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1, 1)\n",
    "        return x * y\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"Enhanced double convolution block with SE attention\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.se = SEBlock(out_channels)\n",
    "        self.residual = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=1),\n",
    "            nn.BatchNorm3d(out_channels)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        main = self.double_conv(x)\n",
    "        main = self.se(main)\n",
    "        residual = self.residual(x)\n",
    "        return F.relu(main + residual)\n",
    "\n",
    "class UNet3D(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=3, features=[16, 32, 64, 128]):\n",
    "        super(UNet3D, self).__init__()\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.decoder = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Encoder\n",
    "        in_channels_temp = in_channels\n",
    "        for feature in features:\n",
    "            self.encoder.append(DoubleConv(in_channels_temp, feature))\n",
    "            in_channels_temp = feature\n",
    "\n",
    "        # Decoder\n",
    "        for feature in reversed(features[:-1]):\n",
    "            # Upsampling\n",
    "            self.decoder.append(\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose3d(\n",
    "                        features[features.index(feature)+1],\n",
    "                        feature,\n",
    "                        kernel_size=2,\n",
    "                        stride=2\n",
    "                    ),\n",
    "                    nn.BatchNorm3d(feature),\n",
    "                    nn.ReLU(inplace=True)\n",
    "                )\n",
    "            )\n",
    "            # Double conv after concatenation\n",
    "            self.decoder.append(DoubleConv(feature * 2, feature))\n",
    "\n",
    "        self.bottleneck = DoubleConv(features[-2], features[-1])\n",
    "        self.final_conv = nn.Conv3d(features[0], out_channels, kernel_size=1)\n",
    "        \n",
    "        # Regularization\n",
    "        self.dropout = nn.Dropout3d(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "\n",
    "        # Encoder\n",
    "        for encoder in self.encoder[:-1]:\n",
    "            x = encoder(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        # Decoder\n",
    "        skip_connections = skip_connections[::-1]\n",
    "        for idx in range(0, len(self.decoder), 2):\n",
    "            x = self.decoder[idx](x)\n",
    "            skip = skip_connections[idx//2]\n",
    "            \n",
    "            # Handle different sizes\n",
    "            if x.shape != skip.shape:\n",
    "                x = F.interpolate(x, size=skip.shape[2:])\n",
    "                \n",
    "            concat_skip = torch.cat((skip, x), dim=1)\n",
    "            x = self.decoder[idx+1](concat_skip)\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        return self.final_conv(x)\n",
    "\n",
    "# Initialize model\n",
    "model = UNet3D().to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the complete U-Net model\n",
    "class UNet3D(nn.Module):\n",
    "    \"\"\"3D U-Net architecture with residual connections and dropout\"\"\"\n",
    "    def __init__(self, in_channels=1, out_channels=3, features=[32, 64, 128, 256]):\n",
    "        super(UNet3D, self).__init__()\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.decoder = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Encoder\n",
    "        in_channels_temp = in_channels\n",
    "        for feature in features:\n",
    "            self.encoder.append(DoubleConv(in_channels_temp, feature))\n",
    "            in_channels_temp = feature\n",
    "\n",
    "        # Decoder\n",
    "        for feature in reversed(features[:-1]):\n",
    "            self.decoder.append(\n",
    "                nn.ConvTranspose3d(\n",
    "                    features[features.index(feature)+1],\n",
    "                    feature,\n",
    "                    kernel_size=2,\n",
    "                    stride=2\n",
    "                )\n",
    "            )\n",
    "            self.decoder.append(DoubleConv(feature * 2, feature))\n",
    "\n",
    "        self.bottleneck = DoubleConv(features[-2], features[-1])\n",
    "        self.final_conv = nn.Conv3d(features[0], out_channels, kernel_size=1)\n",
    "        \n",
    "        # Dropout layers\n",
    "        self.dropout = nn.Dropout3d(p=0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "\n",
    "        # Encoder\n",
    "        for encoder in self.encoder[:-1]:\n",
    "            x = encoder(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        # Decoder\n",
    "        skip_connections = skip_connections[::-1]\n",
    "        for idx in range(0, len(self.decoder), 2):\n",
    "            x = self.decoder[idx](x)\n",
    "            skip = skip_connections[idx//2]\n",
    "            \n",
    "            # Handle different sizes\n",
    "            if x.shape != skip.shape:\n",
    "                x = F.interpolate(x, size=skip.shape[2:])\n",
    "                \n",
    "            concat_skip = torch.cat((skip, x), dim=1)\n",
    "            x = self.decoder[idx+1](concat_skip)\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        return self.final_conv(x)\n",
    "\n",
    "# Initialize model and training components\n",
    "model = UNet3D().to(device)\n",
    "criterion = DiceLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "\n",
    "print(\"\\nModel architecture:\")\n",
    "print(model)\n",
    "print(\"\\nTraining parameters:\")\n",
    "print(f\"Optimizer: AdamW with learning rate 1e-3 and weight decay 0.01\")\n",
    "print(f\"Loss function: Dice Loss\")\n",
    "print(f\"Learning rate scheduler: ReduceLROnPlateau\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Functions and Loop\n",
    "\n",
    "print(\"Setting up training process with loss functions and optimization...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        # Move to GPU and clear gradients\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update metrics\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Print progress and clear cache\n",
    "        if batch_idx % 5 == 0:\n",
    "            print(f'Batch {batch_idx}/{len(loader)}, Loss: {loss.item():.4f}')\n",
    "            torch.cuda.empty_cache()  # Clear GPU cache periodically\n",
    "    \n",
    "    return total_loss / num_batches\n",
    "\n",
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)  # During validation, only get main output\n",
    "            loss = criterion(output, target)\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "    return total_loss / num_batches\n",
    "\n",
    "# Training setup\n",
    "criterion = DiceLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 30\n",
    "best_val_loss = float('inf')\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
    "    val_loss = validate(model, val_loader, criterion)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{n_epochs}:')\n",
    "    print(f'Train Loss: {train_loss:.4f}')\n",
    "    print(f'Val Loss: {val_loss:.4f}')\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= patience:\n",
    "        print(f'Early stopping triggered after {epoch+1} epochs')\n",
    "        break\n",
    "    \n",
    "    # Print current learning rate\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f'Current learning rate: {current_lr:.2e}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Evaluation and Visualization\n",
    "\n",
    "Evaluate the model and visualize results:\n",
    "\n",
    "### Questions to consider:\n",
    "1. How well does the model segment different classes?\n",
    "2. What are the clinical implications of false positives/negatives?\n",
    "3. How could the model be improved?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_volume(model, ct_volume):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(ct_volume.unsqueeze(0).to(device))\n",
    "        pred = F.softmax(pred, dim=1)\n",
    "        pred = torch.argmax(pred, dim=1)\n",
    "    return pred[0].cpu().numpy()\n",
    "\n",
    "# Load a validation sample\n",
    "val_ct, val_seg = val_dataset[0]\n",
    "pred_seg = predict_volume(model, val_ct)\n",
    "\n",
    "# Visualize results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "slice_idx = val_ct.shape[2]//2\n",
    "\n",
    "axes[0].imshow(val_ct[0, :, :, slice_idx], cmap='gray')\n",
    "axes[0].set_title('CT Slice')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(val_seg[:, :, slice_idx], cmap='jet')\n",
    "axes[1].set_title('True Segmentation')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(pred_seg[:, :, slice_idx], cmap='jet')\n",
    "axes[2].set_title('Predicted Segmentation')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Discussion Questions\n",
    "\n",
    "Please answer the following questions based on your implementation and results:\n",
    "\n",
    "1. **Data Analysis**\n",
    "   - What challenges did you encounter with the medical imaging data?\n",
    "   - How did you handle class imbalance?\n",
    "\n",
    "2. **Model Performance**\n",
    "   - How well did the model perform on different classes?\n",
    "   - What were the main sources of error?\n",
    "\n",
    "3. **Clinical Relevance**\n",
    "   - How might this model be useful in a clinical setting?\n",
    "   - What additional validation would be needed?\n",
    "\n",
    "4. **Improvements**\n",
    "   - What modifications could improve the model's performance?\n",
    "   - How could the preprocessing pipeline be enhanced?\n",
    "\n",
    "Write your answers below:\n",
    "\n",
    "1. Data Analysis:\n",
    "   > Your answer here\n",
    "\n",
    "2. Model Performance:\n",
    "   > Your answer here\n",
    "\n",
    "3. Clinical Relevance:\n",
    "   > Your answer here\n",
    "\n",
    "4. Improvements:\n",
    "   > Your answer here\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
